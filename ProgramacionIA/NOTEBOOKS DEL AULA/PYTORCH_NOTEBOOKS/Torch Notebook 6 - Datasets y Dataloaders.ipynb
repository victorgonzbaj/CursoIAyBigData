{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gestión de datos en Pytorch: Datasets y Dataloaders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecfb1d57a6b8d485"
  },
  {
   "cell_type": "markdown",
   "source": [
    "El módulo **torch.utils.data** de PyTorh tiene clases muy útiles para la carga de datos necesaria en los procesos de entrenamiento y validación.   \n",
    "En este notebook vamos a ver dos de las clases más importantes: *torch.utils.data.Dataset* para albergar los datos y *torch.utils.data.DataLoader* para cargar los datos.\n",
    "\n",
    "Las clases **Dataset** permiten instanciar objetos con el conjunto de datos que se van a cargar. PyTorch permite crear dos tipos distintos de datasets:  \n",
    "- Map-style: Implementa los métodos **getitem()** and **len()** y representa un mapeo de claves/índices a valores del conjunto de datos. La clase Dataset sería un ejemplo y es el tipo de dataset que veremos.\n",
    "- Iterable-style: Implementa el método **iter()** y representa un iterable sobre los datos. La clase IterableDataset es un ejemplo.   \n",
    "\n",
    "A continuación vamos a ver un ejemplo de definición de una clase que contiene un conjunto de datos. Esta clase hereda la clase Dataset y sobreescribe el método getitem() que permite obtener una muestra de los datos a partir de la clave/índice y el método len() que devuelve el tamaño de los datos. A modo de ejemplo creamos unos datos con una lista de 1000 valores como muestra y y otra lista de 1000 valores como etiquetas.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be0b3b7dd1e2979f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:54:59.635126Z",
     "start_time": "2024-11-03T18:54:57.988193Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NumbersDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.samples = list(range(1, 1001))\n",
    "        self.labels = list(range(1000, 2001))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos una instancia de la clase que hemos definido. Vemos el tamaño de los datos y varias muestras de los datos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7553ccf12a532651"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "(101, 1100)\n",
      "([123, 124, 125], [1122, 1123, 1124])\n"
     ]
    }
   ],
   "source": [
    "dataset = NumbersDataset()\n",
    "print(len(dataset))\n",
    "print(dataset[100])\n",
    "print(dataset[122:125])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:55:55.528431Z",
     "start_time": "2024-11-03T18:55:55.524407Z"
    }
   },
   "id": "e6c80a8a512aebd9",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "La clase **torch.utils.data.DataLoader** es la clase principal para cargar los datos. A esta clase se le pasa como argumento un objeto Dataset (map-style o iterable style) y tiene varias opciones como:\n",
    "\n",
    "- Definir el orden y la forma de cargar los datos.\n",
    "- Batching automático: Se carga un batch de datos de manera automática o manual.\n",
    "- Realizar la carga de datos en un proceso o en múltiples procesos.\n",
    "- Ubicar los tensores en memoria page-locked para agilizar su transferencia a la GPU.  \n",
    "\n",
    "A continuación, creamos una instancia de la clase torch.utils.data.DataLoader a la que pasamos el objeto dataset que hemos creado. Definimos un tamaño de batch de 10 y shuffle=False para que no se cambie el orden de los datos en cada epoch (recorrido completo de los datos)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac955d4b990d264b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number 1\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]) tensor([1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009])\n",
      "Batch number 2\n",
      "tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20]) tensor([1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019])\n",
      "Batch number 3\n",
      "tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) tensor([1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029])\n",
      "Batch number 4\n",
      "tensor([31, 32, 33, 34, 35, 36, 37, 38, 39, 40]) tensor([1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039])\n",
      "Batch number 5\n",
      "tensor([41, 42, 43, 44, 45, 46, 47, 48, 49, 50]) tensor([1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049])\n",
      "Batch number 6\n",
      "tensor([51, 52, 53, 54, 55, 56, 57, 58, 59, 60]) tensor([1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059])\n",
      "Batch number 7\n",
      "tensor([61, 62, 63, 64, 65, 66, 67, 68, 69, 70]) tensor([1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069])\n",
      "Batch number 8\n",
      "tensor([71, 72, 73, 74, 75, 76, 77, 78, 79, 80]) tensor([1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079])\n",
      "Batch number 9\n",
      "tensor([81, 82, 83, 84, 85, 86, 87, 88, 89, 90]) tensor([1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089])\n",
      "Batch number 10\n",
      "tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]) tensor([1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099])\n",
      "Batch number 11\n",
      "tensor([101, 102, 103, 104, 105, 106, 107, 108, 109, 110]) tensor([1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109])\n"
     ]
    }
   ],
   "source": [
    "batch_size=10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
    "for i, (numbers, labels) in enumerate(train_loader):\n",
    "  if  i<11:\n",
    "    print('Batch number %d'%(i+1))\n",
    "    print(numbers, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:57:18.055786Z",
     "start_time": "2024-11-03T18:57:18.037673Z"
    }
   },
   "id": "b8ed92905b44cdaa",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora, creamos otra instancia pero con *shuffle=True* para que se cambie el orden de los datos en cada epoch."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2856b32271e13a9b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number 1\n",
      "tensor([248, 661, 179, 766, 235, 299, 935, 475, 969, 765]) tensor([1247, 1660, 1178, 1765, 1234, 1298, 1934, 1474, 1968, 1764])\n",
      "Batch number 2\n",
      "tensor([737, 976, 124,  83, 514, 569,  13, 324, 271, 477]) tensor([1736, 1975, 1123, 1082, 1513, 1568, 1012, 1323, 1270, 1476])\n",
      "Batch number 3\n",
      "tensor([351, 480, 507, 520, 236, 690, 358, 984, 944, 553]) tensor([1350, 1479, 1506, 1519, 1235, 1689, 1357, 1983, 1943, 1552])\n",
      "Batch number 4\n",
      "tensor([ 59,  60, 319, 608,  37, 863, 602, 311, 132, 571]) tensor([1058, 1059, 1318, 1607, 1036, 1862, 1601, 1310, 1131, 1570])\n",
      "Batch number 5\n",
      "tensor([442, 995, 655,  51,  55, 270, 788, 651, 688, 425]) tensor([1441, 1994, 1654, 1050, 1054, 1269, 1787, 1650, 1687, 1424])\n",
      "Batch number 6\n",
      "tensor([371, 967, 119, 422, 141, 915, 394, 599, 201, 452]) tensor([1370, 1966, 1118, 1421, 1140, 1914, 1393, 1598, 1200, 1451])\n",
      "Batch number 7\n",
      "tensor([635,  96, 199, 112, 467, 326, 206, 728, 738, 666]) tensor([1634, 1095, 1198, 1111, 1466, 1325, 1205, 1727, 1737, 1665])\n",
      "Batch number 8\n",
      "tensor([156, 449,  47, 310, 824, 652, 140, 852, 827, 802]) tensor([1155, 1448, 1046, 1309, 1823, 1651, 1139, 1851, 1826, 1801])\n",
      "Batch number 9\n",
      "tensor([401, 516, 786, 815, 411, 858, 407, 157, 282, 952]) tensor([1400, 1515, 1785, 1814, 1410, 1857, 1406, 1156, 1281, 1951])\n",
      "Batch number 10\n",
      "tensor([663, 240,  26, 610, 515, 845, 597, 722, 733, 438]) tensor([1662, 1239, 1025, 1609, 1514, 1844, 1596, 1721, 1732, 1437])\n",
      "Batch number 11\n",
      "tensor([473, 627, 450, 843, 662, 680, 711, 213,  39, 708]) tensor([1472, 1626, 1449, 1842, 1661, 1679, 1710, 1212, 1038, 1707])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "for i, (numbers, labels) in enumerate(train_loader):\n",
    "  if  i<11:\n",
    "    print('Batch number %d'%(i+1))\n",
    "    print(numbers, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:57:57.312493Z",
     "start_time": "2024-11-03T18:57:57.288726Z"
    }
   },
   "id": "8144f1d5b8b4e9cc",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "292e696e84061c76"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
