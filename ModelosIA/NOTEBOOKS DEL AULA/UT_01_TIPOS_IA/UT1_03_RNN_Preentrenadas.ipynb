{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIDAD DE TRABAJO 1.    \n",
    "## APTDO. 1.2.4.1 - REDES NEURONALES PREENTRENADAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJEMPLO 1 - Transfer Learning con RESNET50 + TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 18:04:46.346024: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "# 📌 1. Cargar el modelo ResNet50 preentrenado (sin la capa de salida)\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 2. Congelar las capas del modelo base (Feature Extraction) \n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 3. Construir un nuevo modelo agregando capas personalizadas\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),  \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),  \n",
    "    Dense(2, activation='softmax')  # 2 clases: Gato o Perro\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 4. Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 5. Preparar los datos con ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"datasets/perros_gatos/\",  # 📌 Ruta de imágenes (organizadas en carpetas por clases)\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = train_datagen.flow_from_directory(\n",
    "    \"datasets/perros_gatos/\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.5608 - loss: 8.2171 - val_accuracy: 0.5700 - val_loss: 0.7947\n",
      "Epoch 2/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.4850 - loss: 0.9232 - val_accuracy: 0.5100 - val_loss: 0.7046\n",
      "Epoch 3/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.5166 - loss: 0.6892 - val_accuracy: 0.6150 - val_loss: 0.6882\n",
      "Epoch 4/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.5538 - loss: 0.7156 - val_accuracy: 0.7050 - val_loss: 0.6912\n",
      "Epoch 5/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.5648 - loss: 0.6712 - val_accuracy: 0.6050 - val_loss: 0.6892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2b6c268950>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 📌 6. Entrenar el modelo con Transfer Learning\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6255 - loss: 0.7228\n",
      "Precisión en validación: 0.61\n"
     ]
    }
   ],
   "source": [
    "# 📌 7. Evaluar el modelo en datos de validación\n",
    "loss, acc = model.evaluate(val_generator)\n",
    "print(f\"Precisión en validación: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicación del código   \n",
    "\n",
    "- Cargamos ResNet50 sin la última capa (include_top=False) para usarlo como extractor de características.  \n",
    "- Congelamos sus capas (base_model.trainable = False) para que no se ajusten en el nuevo entrenamiento.\n",
    "- Agregamos nuevas capas personalizadas, adaptadas a la nueva tarea de clasificación (2 clases).\n",
    "- Compilamos y entrenamos el modelo solo con las nuevas capas.\n",
    "- Usamos ImageDataGenerator para cargar imágenes desde carpetas y aplicar preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJEMPLO 2 - Transfer Learning con Hugging Face - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos librerías   \n",
    "- **transformers** es una biblioteca de Hugging Face que permite utilizar modelos preentrenados de Procesamiento del Lenguaje Natural (PLN) como BERT, GPT-3, T5, DistilBERT, entre otros.\n",
    "- **pipeline** es una función de alto nivel que facilita el uso de estos modelos sin necesidad de cargar manualmente los pesos y configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tf-keras\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creación de modelo preentrenado para análisis de sentimiento   \n",
    "- Se instancia un pipeline de análisis de sentimiento utilizando un modelo preentrenado por defecto de Hugging Face.\n",
    "- Si es la primera vez que ejecutas este código, el modelo se descargará automáticamente desde los servidores de Hugging Face.\n",
    "- Se carga un modelo es multilingüe y puede procesar textos en español. Es el modelo <a href=\"https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment?utm_source=chatgpt.com\"> ***bert-base-multilingual-uncased-sentiment*** </a>desarrollado por NLP Town. Este modelo está basado en la arquitectura BERT y ha sido ajustado específicamente para el análisis de sentimientos en reseñas de productos en seis idiomas: inglés, neerlandés, alemán, francés, español e italiano. Sus características principales son:\n",
    "\n",
    "  - Arquitectura: Basado en BERT-base-multilingual-uncased, una versión de BERT que maneja múltiples idiomas y no distingue entre mayúsculas y minúsculas.\n",
    "\n",
    "  - Tarea: Clasificación de sentimientos en reseñas de productos, prediciendo una puntuación en una escala de 1 a 5 estrellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelo preentrenado para análisis de sentimiento\n",
    "# analisis_sentimiento = pipeline(\"sentiment-analysis\")\n",
    "analisis_sentimiento = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizar análisis sobre textos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '5 stars', 'score': 0.7860149145126343}]\n"
     ]
    }
   ],
   "source": [
    "# Probar con un texto\n",
    "# resultado = analisis_sentimiento(\"This course is very interesting.\")\n",
    "resultado = analisis_sentimiento(\"Este curso es increíble y muy útil.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '5 stars', 'score': 0.7707265615463257}, {'label': '2 stars', 'score': 0.5164674520492554}, {'label': '4 stars', 'score': 0.5573275089263916}]\n"
     ]
    }
   ],
   "source": [
    "# Analizar varios textos\n",
    "textos = [\"Me encanta este curso.\", \"No me gusta la interfaz de usuario.\", \"Estoy satisfecho con el resultado.\"]\n",
    "resultados = analisis_sentimiento(textos)\n",
    "print(resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
