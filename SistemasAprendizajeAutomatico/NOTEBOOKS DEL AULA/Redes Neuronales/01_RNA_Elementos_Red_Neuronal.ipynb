{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEMENTOS RED NEURONAL ARTIFICIAL   \n",
    "\n",
    "## Deep Learning y Redes Neuronales Artificiales\n",
    "En general, hoy en día estamos manejando redes neuronales artificiales con muchísimas capas que, literalmente, están apiladas una encima de la otra; de aquí el concepto de **deep** (profundidad de la red), donde cada una de ellas está compuesta, a su vez, por muchísimas neuronas, cada una con sus parámetros que, a su vez, realizan una transformación simple de los datos que reciben de neuronas de la capa anterior para pasarlos a las de la capa posterior. La unión de todas permite descubrir patrones complejos en los datos de entrada.    \n",
    "\n",
    "En la práctica, todos los algoritmos de Deep Learning son redes neuronales que comparten algunas propiedades básicas comunes, como que todas consisten en neuronas interconectadas que se organizan en capas.\n",
    "En lo que difieren es en la arquitectura de la red (la forma en que las neuronas están organizadas en la red) y, a veces, en la forma en que se entrenan. Con eso en mente, enumeramos a continuación las principales clases de redes neuronales que presentaremos a lo largo del libro. Aunque no es una lista exhaustiva, representan la mayor parte de los algoritmos en uso hoy en día:   \n",
    "\n",
    "- ***Perceptrón multicapa (MLP, del inglés Multi-layer perceptron)***: un tipo de red neuronal con capas densamente conectadas.\n",
    "- ***Redes neuronales convolucionales (CNN del inglés Convolutional Neural Networks)***: una CNN es una red neuronal con varios tipos de capas especiales. Hoy en día este tipo de red está siendo muy usada por la industria en diferentes tipos de tarea, especialmente de visión por computador.\n",
    "- ***Redes neuronales recurrentes (RNN del inglés Recurrent Neural Networks)***: este tipo de red tiene un estado interno (o memoria) que se crea con los datos de entrada ya vistos por la red. La salida de una RNN es una combinación de su estado interno y los datos de entrada. Al mismo tiempo, el estado interno cambia para incorporar datos recién entrados. Debido a estas propiedades, las redes neuronales recurrentes son buenas candidatas para tareas que funcionan en datos secuenciales, como texto o datos de series de tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura y elementos de una Red Neuronal Artificial    \n",
    "\n",
    "<img src=\"img/DIAGRAMARNA.jpeg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la figura anterior se puede ver la estructura de la red, de donde extraemos los siguientes cuatro elementos:\n",
    "\n",
    "- **Capas**: Es el elemento fundamental. Hay ciertas variantes, ciertos hiperparámetros como se suele expresar, para definir la red en lo relativo a las capas (número de capas, número de neuronas por capa, etc). Pero de cara a centrarnos en los elementos de la RN, nos fijaremos básicamente en el tipo de capa (o combinaciones de capa). \n",
    "- **Función de activación**: No aparece en el dibujo, pero es la función que rige la salida de las neuronas, especialmente relevante en las capas de salida. Dado que tiene relevancia en relación con el problema a tratar, será analizada detalladamente.\n",
    "- **Función de pérdida**: La función que calcula cuán lejos está el resultado que produce la red del esperado, y que constituye la entrada fundamental para el aprendizaje.\n",
    "- **Optimizador**: Que, en función de lo que obtiene como entrada de la función de pérdida, ‘decide’ en qué cuantía y dirección modificar los parámetros de las capas, típicamente sus pesos.   \n",
    "\n",
    "Existen muchas más variantes y muchos más hiperparámetros a elegir para definir una red neuronal pero, inicialmente, nos referiremos a esos cuatro elementos a la hora de analizar los componentes de las redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capas de una Red Neuronal Artificial   \n",
    "   \n",
    "Como ya sabemos, la unidad mínima en una red neuronal sería, en teoría, la neurona, que conceptualmente se corresponde con una unidad que recibe unos datos de entrada (en la metáfora neuronal serían las salidas de otras neuronas) y proporciona un valor de salida.   \n",
    "Realmente, a la hora de trabajar, más que con neuronas individuales, se trabaja con *capas*, que se corresponden intuitivamente con lo que la palabra capa indica, es decir, un *conjunto de neuronas en un mismo nivel*, que tienen características homogéneas entre sí y que se conectan con las neuronas de la capa precedente. Desde un punto de vista matemático, una capa se traduce en un módulo de procesamiento matemático que toma como entrada un tensor (que sería la salida de la capa anterior) y devuelve como salida otro tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre los elementos que definen la tipología de una capa tenemos, por supuesto, el tipo de cálculos que aplican sus neuronas, pero también el patrón de conexión entre sí y, sobre todo, con la capa precedente.   \n",
    "Disponemos, de entrada, de tres familias de capas, a saber:   \n",
    "- **Densa (Perceptrón)**: En ellas todas las neuronas de una capa están conectadas a todas las neuronas de la capa anterior. Son capas que no asumen ningún tipo de estructura específica en las características de entrada. Se utilizan fundamentalmente en problemas de clasificación ya sea asumiendo la totalidad de las capas de la red o bien como fase final de clasificación en una red con capas de otros tipos.\n",
    "- **Convolución**: capas que aplican transformaciones geométricas locales en espacios acotados de sus datos de entrada. Es decir, recorren sus datos de entrada aplicando sucesivamente pequeñas transformaciones a subconjuntos pequeños de ese espacio de entrada hasta finalizar el recorrido. Su comportamiento tiende a ir extrayendo, mediante la acción de capas sucesivas, características significativas del espacio de entrada. Suelen apoyarse en otros tipos de capas auxiliares como son las *capas de ‘pooling‘ (reducción del espacio de datos)* y *‘flatten‘ (conversión de tensores n-dimensionales en vectores)*.Su aplicación más típica es en tratamiento de imágenes y visión artificial, pero también su utilizan en procesamiento de sonidos, de textos u otro tipo de datos secuenciales.\n",
    "- **Recurrente (RNR)**: Capa específicamente diseñada para el tratamiento de secuencias de entradas, típicamente temporales. Las capas recurrentes se denominan así porque su salida en un momento dado depende, no sólo de las entradas en ese momento, sino de su salida en el paso anterior. Son capas que, además, conservan un estado. Se utilizan en todo tipo de tratamiento de series temporales, siendo quizá lo más relevante, todo lo que tiene que ver con el procesamiento de texto y lenguaje o el análisis de sentimiento, pero también, por ejemplo, en la predicción del tiempo e incluso en redes generativas de texto. Existen algunas variantes de las que las más comunes son las dos siguientes:   \n",
    "\n",
    "    - *Long Short-Term Memory (LSTM)*: En que la información recurrente se transmite no sólo al paso anterior sino a varios pasos anteriores.\n",
    "    - *Gated Recurrent Unit (GRU)*: siguen la misma idea que las LSTM pero son computacionalmente más eficientes.\n",
    "\n",
    "<img src=\"img/denseLayer.svg\" width=800>\n",
    "   \n",
    "### Conv Layer (Convolutional Network)\n",
    "<img src=\"img/convLayer.png\" width=800>   \n",
    "\n",
    "### RNN Layer (Recurrent Network)\n",
    "<img src=\"img/RNNLayer.png\" width=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de Activación   \n",
    "\n",
    "Como se recoge en la figura inferior (autor: Jordi Torres), una neurona artificial habitualmente divide su procesamiento en dos partes:   \n",
    "- Por un lado, un tratamiento de las entradas (que puede ser, por ejemplo, una suma ponderada como se muestra en la figura o una convolución) y, \n",
    "- al resultado de esa primera función, aplicarle otra pequeña transformación para obtener el valor de salida de nuestra neurona. Esa segunda transformación, esa segunda función que en la figura se representa dentro de un rectángulo, es a lo que se denomina **función de activación** y es un segundo elemento de diseño relevante.   \n",
    "\n",
    "\n",
    "<img src=\"img/neuronaArtificialJT.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disponemos de variedad de funciones de activación, algunas de las cuales se muestran en la figura siguiente:    \n",
    "\n",
    "<img src=\"img/activationFunction.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos, a continuación, algunas de las más habituales.\n",
    "\n",
    "- **Función Lineal**: Se trata, quizá, del caso más simple, en que la función de activación básicamente, da una salida igual a la entrada, es decir, actúa como función identidad trasladando a su salida el resultado obtenido en la primera parte del procesamiento de la neurona (la suma ponderada de entradas, por ejemplo).\n",
    "- **Función Rectified Linear Unit (‘ReLU’)**: Aunque el nombre pueda llamar a engaño, se trata en realidad de una función no lineal. En este caso, el valor de la función de activación es igual a su entrada mientras ésta sea mayor que cero (en ese caso sí actúa como lineal) pero, en caso contrario, el valor de activación es nulo. Su labor, en el fondo, no es más que eliminar valores negativos. Es difícil de explicar brevemente, pero este tipo de no linealidades aumenta las posibilidades de la red. En concreto, esta función, muy popular, da buenos resultados, por ejemplo, en redes de convolución y, por tanto, en tareas como visión artificial o reconocimiento de voz.    \n",
    "Aparte de la ReLU, existen otras muchas funciones de activación que juegan con la linealidad y no linealidad de forma parecida, como pueden ser, por ejemplo, la *‘Leaky ReLU‘* en que para los valores negativos se proporciona una pendiente diferente (más tendida) que para los positivos o la *‘Exponential LU‘*.\n",
    "- **Función Sigmoidea (logística)**: Se trata de una función continua y derivable (importante en los algoritmos de aprendizaje), con un rango entre 0 y 1 y generalmente cerca de esos extremos (0 ó 1). Esto la hace muy adecuada para problemas de clasificación. Por ejemplo, para una clasificación binaria, una única neurona de salida con esta función de activación sigmoidea tendería a dar muy bien el resultado (cercano a uno una categoría, cercana a cero la otra). También se utiliza en problemas de regresión con salida entre 0 y 1.\n",
    "- **Función Tangente Hiperbólica**: Una función con una forma parecida a la sigmoidea pero que, en este caso, proporciona valores entre 1 y -1, es decir, admite valores negativos en la salida.\n",
    "- **Función ‘softmax’ (función exponencial normalizada)**: Es una función de activación un poco particular, puesto que la salida no sólo depende de las entradas de la neurona sino también de la salida de las otras neuronas de la misma capa. Cuando se aplica una función de activación, la suma de las activaciones de la capa debe ser 1. Se utiliza en problemas de clasificación en múltiples categorías y etiquetas, en las que cada neurona de salida representa una categoría. La que tiene el valor más alto es la que representa con más probabilidad la categoría que corresponde a los datos mostrados en la entrada de la red.     \n",
    "\n",
    "Existen más funciones de activación, claro, pero con éstas, inicialmente, se cubren los casos más habituales.   \n",
    "\n",
    "\n",
    "Las funciones de activación desempeñan un papel importante a la hora de evitar el **sobreajuste** en los modelos de aprendizaje profundo. He aquí varias formas en las que contribuyen a este proceso:\n",
    "\n",
    "### Introducción de la no linealidad y la complejidad   \n",
    "\n",
    "Las funciones de activación introducen la no linealidad en el modelo, lo que permite a la red neuronal captar relaciones complejas y no lineales entre las variables de entrada y las de salida. De este modo, el modelo puede generalizarse mejor a datos desconocidos, reduciendo el riesgo de ajuste excesivo a ejemplos de entrenamiento específicos.   \n",
    "\n",
    "### Regulación natural\n",
    "  \n",
    "Algunas funciones de activación, como ReLU y sus variantes, tienen propiedades que actúan de forma natural como reguladores para evitar la sobreadaptación:\n",
    "\n",
    "- ReLU (Rectified Linear Unit) ignora los valores negativos, lo que puede hacer que el modelo sea más robusto al limitar la activación de las neuronas a patrones específicos presentes en los datos de entrenamiento.\n",
    "- Leaky ReLU y ELU (Exponential Linear Unit) permiten una activación distinta de cero incluso para valores negativos, evitando la inactivación completa de las neuronas y permitiendo una mejor adaptación a las variaciones de los datos.\n",
    "‍\n",
    "### Evitar las \"neuronas muertas\"\n",
    "Las \"neuronas muertas\", en las que una neurona deja de contribuir al aprendizaje porque nunca se activa, pueden provocar un ajuste excesivo al no captar correctamente los matices de los datos. Las variantes de ReLU, como Leaky ReLU y ELU, están diseñadas para evitarlo manteniendo cierta actividad incluso para valores de entrada negativos, mejorando así la capacidad de generalización del modelo.\n",
    "\n",
    "### Estabilizar la convergencia\n",
    "Unas funciones de activación bien elegidas pueden contribuir a una convergencia más estable del modelo durante el entrenamiento. Una convergencia más estable reduce la probabilidad de que el modelo sobreaprenda no sólo los datos de entrenamiento, sino también el ruido o los artefactos específicos del conjunto de entrenamiento.\n",
    "\n",
    "### ***Selección basada en el problema y los datos***   \n",
    "\n",
    "La elección de la función de activación debe adaptarse al tipo de problema y a las características de los datos:\n",
    "\n",
    "- Para tareas en las que se requieren representaciones más complejas, pueden preferirse funciones como Tanh o ELU por su capacidad para mantener gradientes estables y modelar patrones más sutiles.\n",
    "- Para las redes neuronales convolucionales utilizadas en Computer Vision, se suele elegir ReLU por su sencillez y eficacia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida   \n",
    "\n",
    "\n",
    "La **función de pérdida (loss function)**, también denominada función objetivo, en esencia, nos dice, durante el proceso de entrenamiento de la red, lo lejos que está en un momento dado, lo que la red nos ofrece como salida y el resultado que nosotros consideramos que es el correcto o deseado. El valor de la función de pérdida será luego un dato de entrada en el algoritmo de aprendizaje.\n",
    "\n",
    "Dado que los algoritmos de aprendizaje como el descenso de gradiente, calculan la derivada de la función de pérdida, ésta debe ser una función continua y derivable.    \n",
    "\n",
    "Hay una gran variedad de funciones de pérdida posibles pero para nosotros vamos a seleccionar las siguientes:   \n",
    "\n",
    "\n",
    "- **Error Cuadrático Medio (‘Mean Square Error‘, MSE)**: Una función muy conocida que calcula la distancia ‘geométrica’ al valor objetivo. Hablar de distancia geométrica es una forma de visualizarlo que nos orienta cuando pensamos en dos o tres dimensiones. Más allá de esas dimensiones, es sólo una forma de entenderlo. Además, decimos distancia, pero en realidad es la distancia elevada al cuadrado. Una variante de ésta seria la que, en lugar del cuadrado de la distancia, elige el valor absoluto (‘Absolute Error‘). MSE se puede usar, por ejemplo, en problemas de regresión a valores arbitrarios y con una última capa sin función de activación.\n",
    "- **Entropía cruzada Categórica (‘Categorical Cross Entropy‘)**: es una medida de la distancia entre distribuciones de probabilidad. La entropía cruzada suele ser adecuada en modelos de redes cuya salida representa una probabilidad, como cuando hacemos una clasificación categórica con función de activación ‘softmax’. Se puede utilizar, por ejemplo, en problemas de clasificación categórica con una sola etiqueta de salida y precedida de una función de activación ‘Softmax’.\n",
    "- **Entropía cruzada binaria (‘Binary Cross Entropy‘)**:  Una variante de la anterior pero en que tratamos con clasificación binaria y , por tanto, la función de activación sería una sigmoide.\n",
    "- **Entropía Cruzada Categórica Dispersa (‘Sparse Categorical Cross Entropy‘)**: Una variante que se suele usar en el caso de trabajar con números enteros.   \n",
    "\n",
    "\n",
    "Hay mucho más aparato matemático detrás de las funciones de pérdida, y más opciones posibles pero para nuestros objetivos en este módulo y en el curso, estás serán más que suficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizadores   \n",
    "\n",
    "Los optimizadores son una pieza nuclear del aprendizaje que, tomando como dato de entrada el valor de la función de pérdida, decide cómo modificar los pesos de la red para conseguir que el resultado se acerque, en cada paso, un poquito más al objetivo deseado.   \n",
    "\n",
    "El algoritmo más ‘típico’ que podemos en este caso que el **descenso de gradiente (‘Gradient descent‘)** que, en el fondo, no es más, como intuición, que imaginar el perfil de la función de pérdida como una curva o superficie e ir ‘bajando’ en pequeños pasos por esa curva/superficie, en la dirección de máxima inclinación, hasta encontrar el ‘valle’, el punto más bajo, momento en que habríamos minimizado el error.\n",
    "\n",
    "El descenso de gradiente *(‘Gradient Descent’, GD)* es un optimizador popular y la base de algunos otros. Vamos a ver, brevemente, una relación de otros optimizadores:   \n",
    "\n",
    "- **BGD (‘Batch Gradient Descent‘)**: Es una variante del gradient descent en que, en cada iteración, tomamos el conjunto entero de datos de aprendizaje para calcular el valor del gradiente. Es un algoritmo relativamente sencillo de entender, pero de convergencia lenta.\n",
    "- **SGD (‘Stochastic Gradient Descent‘)**: Es el extremo contrario, es decir, en lugar de usar todo el conjunto de datos para calcular el gradiente y actualizar pesos como hace BGD, en este caso en cada iteración utilizamos un único punto de datos con lo que tenemos una convergencia mucho más rápida. A cambio, tiende a presentar ciertas inestabilidades y fluctuaciones.\n",
    "- **‘Mini-batch Gradient Descent‘**: Es el punto intermedio entre los dos anteriores. En este caso, en cada iteración elegimos un conjunto más o menos reducido de puntos de datos.\n",
    "- **Nadam (‘Nesterov-accelerated adaptive moment stimation’)**: Este es un optimizador que utiliza el concepto de ‘momento‘. La idea intuitiva es acelerar más o menos el descenso de la curva de gradiente, según la pendiente de la misma, yendo más rápido en las direcciones en que la curva de la función de pérdida es más escarpada y más lento en las direcciones en que la curva presenta un perfil más suave. Y la forma de hacerlo matemáticamente es teniendo en cuenta, no sólo la pendiente actual, sino también la pendiente de las iteraciones anteriores con lo cual tenemos una cierta estimación de aceleración o deceleración.\n",
    "- **Adagrad (‘ADAptive GRADient algorithm‘)**: Un método que introduce el aprendizaje adaptativo, en que el nivel de variación de los parámetros depende de estos. La idea geométrica es que, si en el descenso de gradiente avanzamos en la dirección de la mayor pendiente en cada momento, pudiendo esa pendiente no apuntar directamente al mínimo global, en Adagrad intentamos que la dirección de descenso, aunque no sea la máxima, sí apunte más en la dirección del mínimo. Presenta, eso si, el problema de una tasa de aprendizaje cada vez menor, que es lo que intentan resolver los siguientes optimizadores.\n",
    "- **RMSprop (‘Root Mean Square prop‘)**: Utiliza una media móvil de los cuadrados del gradiente y normaliza ese valor empleando para ello las magnitudes recientes de los gradientes anteriores. La normalización se realiza, evidentemente, por que si no, el hecho de elevar al cuadrado hace que, caso de no normalizar, tengamos un valor de gradiente exageradamente alto (el cuadrado, en concreto).\n",
    "- **Adam (‘ADAptive Moment stimation’)**: Viene a ser una combinación de Adagrad y RMSprop. Utiliza una media móvil exponencial de los gradientes para ajustar las tasas de aprendizaje. Es un algoritmo computacionalmente eficiente y que usa poca memoria. Y es uno de los optimizadores más populares hoy día.\n",
    "- **Adadelta**: Una extensión de Adagrad más robusta que usa una ventana móvil de actualizaciones de gradientes.\n",
    "- **Adamax**: Una variante algo sutil de Adam, en que en lugar de un momento de segundo orden, se utiliza un momento de orden infinito.   \n",
    "\n",
    "\n",
    "Por detrás de los optimizadores, como puede intuirse, existe un cierto aparataje matemático y no es fácil describirlos de una forma realmente sencilla. Al igual que con los elementos anteriores, para este curso entendemos que la información proporcionada es la estrictamente necesaria.\n",
    "\n",
    "\n",
    "Aunque existen multitud de adaptaciones, suele recomendarse:\n",
    "\n",
    "La elección del algoritmo de optimización puede tener un impacto muy grande en el aprendizaje de los modelos, sobretodo en deep learning. Puede encontrarse una excelente descripción más detallada en el libro gratuito [Dive into Deep Learning](https://d2l.ai/chapter_optimization/index.html).    \n",
    "\n",
    "También es recomendable consultar la API de [Keras](https://keras.io/api/optimizers/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida / Función de activación (Tabla resumen y aplicación)\n",
    "\n",
    "- Dependiente del problema\n",
    " - Clasificación binaria: función activación ultima capa (sigmoide), función de perdida (binary_crossentropy)\n",
    " - Clasificacion multiclase: función activación ultima capa (softmax), función de perdida (categorical_crossentropy)\n",
    " - Regresión con valores arbitrarios: función activación ultima capa (none), función de perdida (mse)\n",
    " - Regresión valores 0 a 1: función activación ultima capa (sigmoide), función de perdida (mse o binary_crossentropy)    \n",
    "\n",
    " \n",
    "| TIPO PROBLEMA | F. ACTIVACIÓN | F. PÉRDIDA |\n",
    "|---------------|---------------|------------|\n",
    "| CLASIFICACION BINARIA | SIGMOIDE | BINARY CROSSENTROPY |\n",
    "| CLASIFICACIÓN MULTICLASE| SOFTMAX | CATEGORICAL CROSSENTROPY|\n",
    "| REGRESIÓN CON VALORES ARBITRARIOS | NINGUNA | MSE|\n",
    "| REGRESION CON VALORES 0 A 1 | SIGMOIDE | MSE / BINARY CROSSENTROPY|\n",
    "\n",
    " \n",
    " Información en Keras https://keras.io/losses/\n",
    "\n",
    "## Criterios (extendidos) para la selección de la función de activación\n",
    "\n",
    " Las distintas funciones de activación de las redes neuronales tienen una gran variedad de aplicaciones prácticas, adaptadas a distintos tipos de problemas y arquitecturas de modelos. He aquí algunos ejemplos de aplicaciones prácticas para cada una de las principales funciones de activación:\n",
    "\n",
    "\n",
    "### Sigmoide\n",
    "- Clasificación binaria: se utiliza como última capa para producir probabilidades (entre 0 y 1) que indican la clase predictiva.\n",
    "- Detección de objetos: Se puede utilizar para predecir la probabilidad de que un objeto esté presente en una región de interés.\n",
    "- Reconocimiento de textos: se utiliza para estimar la probabilidad de aparición de una palabra o entidad específica.\n",
    "‍\n",
    "\n",
    "### Tanh(tangente hiperbólica)\n",
    "- Redes neuronales tradicionales: suelen utilizarse en las capas ocultas para introducir la no linealidad y normalizar los valores de entrada entre -1 y 1.\n",
    "- Reconocimiento del habla: se utiliza para clasificar fonemas y palabras en los sistemas de reconocimiento del habla.\n",
    "- Tratamiento de señales: se aplica a la segmentación y clasificación de señales en medicina o telecomunicaciones.\n",
    "‍\n",
    "\n",
    "### ReLU(Unidad lineal rectificada)\n",
    "- Redes neuronales convolucionales (CNNs) : Muy populares en CNNs de capa oculta para extraer características visuales en visión por computador.\n",
    "- Detección de objetos: se utiliza para extraer características robustas y reducir el tiempo de cálculo en los modelos de detección de objetos.\n",
    "- Análisis del lenguaje natural: se utiliza para la clasificación de textos y la modelización de sentimientos por su sencillez y rendimiento.\n",
    "‍\n",
    "\n",
    "### Leaky ReLU\n",
    "- Redes neuronales profundas: se utilizan para paliar el problema de la \"neurona muerta\" asociado a ReLU, mejorando la solidez y estabilidad del aprendizaje.\n",
    "- Generación de imágenes: se utiliza en los modelos de generación de imágenes para mantener una distribución más estable y diversa de las muestras generadas.\n",
    "- Predicción de series temporales: se utiliza para modelizar tendencias y variaciones en datos de series temporales gracias a su capacidad para manejar entradas negativas.\n",
    "‍\n",
    "\n",
    "### ELU(Unidad lineal exponencial)\n",
    "- Redes neuronales profundas: se utiliza como alternativa a ReLU para lograr una convergencia más rápida y estable al entrenar redes profundas.\n",
    "- Procesamiento del lenguaje natural: Se aplica en modelos de procesamiento del lenguaje para el análisis semántico y la generación de textos debido a su capacidad para mantener gradientes estables.\n",
    "- Predicción de series temporales: se utiliza para captar tendencias y relaciones no lineales en datos de series temporales con un rendimiento mejorado respecto a otras funciones.\n",
    "‍\n",
    "\n",
    "### Softmax\n",
    "- Clasificación multiclase: se utiliza como capa final para normalizar la salida en probabilidades para varias clases, a menudo se utiliza en redes de clasificación.\n",
    "- Modelos de recomendación: se utilizan para evaluar y clasificar las preferencias de los usuarios en los sistemas de recomendación.\n",
    "- Análisis de sentimientos: Se utiliza para predecir y clasificar el sentimiento a partir de texto en línea, como reseñas de productos o comentarios sociales.\n",
    "‍\n",
    "\n",
    "### PReLU(Unidad lineal paramétrica rectificada)\n",
    "- Redes neuronales profundas: se utilizan como alternativa a ReLU para paliar el problema de la \"neurona muerta\" permitiendo una ligera pendiente negativa para las entradas negativas, lo que mejora la robustez del modelo.\n",
    "- Detección de objetos: se utiliza para extraer características robustas y mejorar la precisión de los modelos de detección de objetos en Computer Vision.\n",
    "- Procesamiento del lenguaje natural: se utiliza en redes neuronales recurrentes para modelar dependencias a largo plazo y mejorar la precisión de las predicciones de texto.\n",
    "‍\n",
    "\n",
    "### Swish\n",
    "- Redes neuronales profundas: Reconocido por su eficacia y rendimiento en redes profundas al amplificar las señales positivas y mejorar la no linealidad.\n",
    "- Clasificación de imágenes: se utiliza para la clasificación de imágenes y el reconocimiento de objetos en redes neuronales convolucionales, mejorando a menudo el rendimiento respecto a ReLU.\n",
    "- Modelización de series temporales: se aplica para captar relaciones complejas y no lineales en los datos de series temporales, lo que permite mejorar la predicción y la generalización.\n",
    "‍\n",
    "\n",
    "Al elegir adecuadamente entre estas funciones de activación en función del tipo de problema y de las características de los datos, se pueden optimizar el rendimiento de los modelos de Deep Learning minimizando el riesgo de sobreajuste y mejorando la capacidad de generalización a datos no vistos.\n",
    "\n",
    "Debemos tener en cuenta que cada función de activación aporta ventajas específicas que pueden aprovecharse para satisfacer los diversos requisitos de las aplicaciones reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de una Red Neuronal Sencilla con TENSORFLOW y KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorFlow** es un ecosistema propuesto por Google que se ha convertido en el entorno más popular para desarrolladores de aplicaciones que requieran Deep Learning. Desde su lanzamiento inicial en 2015 por parte del equipo de Google Brain, el paquete cuenta con decenas de millones de descargas y con alrededor de dos mil contribuidores.   \n",
    "\n",
    "**Keras** ofrece una API cuya curva de aprendizaje es muy suave en comparación con otras. Los modelos de Deep Learning son complejos y, si se quieren programar a bajo nivel, requieren un conocimiento matemático de base importante para manejarse fácilmente. Por suerte para nosotros, Keras encapsula las sofisticadas matemáticas de tal manera que el desarrollador de una red neuronal solo necesita saber construir un modelo a partir de componentes preexistentes y acertar en su parametrización.   \n",
    "La implementación de referencia de la librería de Keras fue desarrollada y es mantenida por François Chollet76, ingeniero de Google, y su código ha sido liberado bajo la licencia permisiva del MIT. Su documentación y especificaciones están disponibles en la página web oficial https://keras.io   \n",
    "\n",
    "*tf.keras* es la implementación de TensorFlow de las especificaciones API de Keras. Esta es una API de alto nivel para construir y entrenar modelos que incluye soporte para funcionalidades específicas de TensorFlow, como eager execution o procesamiento de datos con tf.data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAMOS LIBRERIAS\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential  \n",
    "from keras import layers\n",
    "from keras.layers import Dense  \n",
    "import numpy  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "numpy.random.seed(7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos dataset \"Pima Indians Diabetes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"datasets/pima-indians-diabetes.csv\", delimiter=\",\")  \n",
    "X = dataset[:,0:8]  \n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos modelo de Red Neuronal (formato antiguo vs. formato nuevo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  \n",
    "model.add(Dense(12, input_dim=8, activation='relu'))  \n",
    "model.add(Dense(8, activation='relu'))  \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Input(shape=(8,)),\n",
    "    keras.layers.Dense(12, activation='relu'),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilamos el modelo RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6054 - loss: 1.5215\n",
      "Epoch 2/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5721 - loss: 0.9674\n",
      "Epoch 3/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6445 - loss: 0.8532\n",
      "Epoch 4/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5899 - loss: 0.8218\n",
      "Epoch 5/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6356 - loss: 0.7893\n",
      "Epoch 6/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6415 - loss: 0.7107\n",
      "Epoch 7/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6476 - loss: 0.7754\n",
      "Epoch 8/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6511 - loss: 0.7444\n",
      "Epoch 9/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6523 - loss: 0.7102\n",
      "Epoch 10/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6496 - loss: 0.6756\n",
      "Epoch 11/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6812 - loss: 0.6501\n",
      "Epoch 12/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6792 - loss: 0.6345\n",
      "Epoch 13/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6677 - loss: 0.6622\n",
      "Epoch 14/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6923 - loss: 0.5943\n",
      "Epoch 15/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7064 - loss: 0.5872\n",
      "Epoch 16/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6872 - loss: 0.6340\n",
      "Epoch 17/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7267 - loss: 0.5854\n",
      "Epoch 18/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7327 - loss: 0.5765\n",
      "Epoch 19/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7392 - loss: 0.6105\n",
      "Epoch 20/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6801 - loss: 0.5993\n",
      "Epoch 21/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6966 - loss: 0.5750\n",
      "Epoch 22/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6936 - loss: 0.5974\n",
      "Epoch 23/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7117 - loss: 0.5772\n",
      "Epoch 24/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7268 - loss: 0.5669\n",
      "Epoch 25/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6908 - loss: 0.5756\n",
      "Epoch 26/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6960 - loss: 0.5986\n",
      "Epoch 27/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6820 - loss: 0.5681\n",
      "Epoch 28/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7261 - loss: 0.5520\n",
      "Epoch 29/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7088 - loss: 0.5599\n",
      "Epoch 30/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6978 - loss: 0.5953\n",
      "Epoch 31/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7161 - loss: 0.5555\n",
      "Epoch 32/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7302 - loss: 0.5653\n",
      "Epoch 33/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7101 - loss: 0.5651\n",
      "Epoch 34/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6970 - loss: 0.5725\n",
      "Epoch 35/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7506 - loss: 0.5321\n",
      "Epoch 36/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7165 - loss: 0.5768\n",
      "Epoch 37/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7311 - loss: 0.5317\n",
      "Epoch 38/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7292 - loss: 0.5412\n",
      "Epoch 39/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7516 - loss: 0.5225\n",
      "Epoch 40/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6954 - loss: 0.5666\n",
      "Epoch 41/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7423 - loss: 0.5243\n",
      "Epoch 42/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6525 - loss: 0.6015\n",
      "Epoch 43/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7454 - loss: 0.5105\n",
      "Epoch 44/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7047 - loss: 0.5609\n",
      "Epoch 45/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7129 - loss: 0.5528\n",
      "Epoch 46/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7325 - loss: 0.5298\n",
      "Epoch 47/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7469 - loss: 0.5102\n",
      "Epoch 48/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7452 - loss: 0.5226\n",
      "Epoch 49/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7198 - loss: 0.5466\n",
      "Epoch 50/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7220 - loss: 0.5507\n",
      "Epoch 51/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7322 - loss: 0.5298\n",
      "Epoch 52/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7233 - loss: 0.5354\n",
      "Epoch 53/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7302 - loss: 0.5343\n",
      "Epoch 54/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7390 - loss: 0.5437\n",
      "Epoch 55/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7421 - loss: 0.5356\n",
      "Epoch 56/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7488 - loss: 0.5246\n",
      "Epoch 57/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7416 - loss: 0.5391\n",
      "Epoch 58/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7253 - loss: 0.5435\n",
      "Epoch 59/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7397 - loss: 0.5369\n",
      "Epoch 60/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7309 - loss: 0.5200\n",
      "Epoch 61/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7024 - loss: 0.5489\n",
      "Epoch 62/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7073 - loss: 0.5422\n",
      "Epoch 63/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7763 - loss: 0.4989\n",
      "Epoch 64/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7407 - loss: 0.5193\n",
      "Epoch 65/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7587 - loss: 0.5354\n",
      "Epoch 66/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7704 - loss: 0.4964\n",
      "Epoch 67/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7341 - loss: 0.5298\n",
      "Epoch 68/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7443 - loss: 0.5141\n",
      "Epoch 69/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7341 - loss: 0.5185\n",
      "Epoch 70/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7319 - loss: 0.5152\n",
      "Epoch 71/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7591 - loss: 0.5268\n",
      "Epoch 72/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7410 - loss: 0.5243\n",
      "Epoch 73/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7590 - loss: 0.5133\n",
      "Epoch 74/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7672 - loss: 0.5220\n",
      "Epoch 75/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7716 - loss: 0.4987\n",
      "Epoch 76/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7104 - loss: 0.5273\n",
      "Epoch 77/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7360 - loss: 0.5250\n",
      "Epoch 78/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7521 - loss: 0.5108\n",
      "Epoch 79/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7613 - loss: 0.4936\n",
      "Epoch 80/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7603 - loss: 0.4879\n",
      "Epoch 81/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7489 - loss: 0.5185\n",
      "Epoch 82/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7679 - loss: 0.4825\n",
      "Epoch 83/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7629 - loss: 0.5010\n",
      "Epoch 84/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7168 - loss: 0.5383\n",
      "Epoch 85/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7525 - loss: 0.4866\n",
      "Epoch 86/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7779 - loss: 0.4725\n",
      "Epoch 87/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7248 - loss: 0.5287\n",
      "Epoch 88/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7426 - loss: 0.4923\n",
      "Epoch 89/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7455 - loss: 0.4862\n",
      "Epoch 90/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7839 - loss: 0.4722\n",
      "Epoch 91/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7790 - loss: 0.4838\n",
      "Epoch 92/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7275 - loss: 0.5090\n",
      "Epoch 93/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7298 - loss: 0.5308\n",
      "Epoch 94/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7450 - loss: 0.5043\n",
      "Epoch 95/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7759 - loss: 0.4734\n",
      "Epoch 96/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7769 - loss: 0.4749\n",
      "Epoch 97/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7436 - loss: 0.5005\n",
      "Epoch 98/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7573 - loss: 0.4943\n",
      "Epoch 99/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7662 - loss: 0.4889\n",
      "Epoch 100/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7632 - loss: 0.5091\n",
      "Epoch 101/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7416 - loss: 0.5143\n",
      "Epoch 102/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7544 - loss: 0.5048\n",
      "Epoch 103/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7778 - loss: 0.4921\n",
      "Epoch 104/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7602 - loss: 0.4924\n",
      "Epoch 105/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7902 - loss: 0.4873\n",
      "Epoch 106/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7769 - loss: 0.4795\n",
      "Epoch 107/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7419 - loss: 0.5030\n",
      "Epoch 108/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7456 - loss: 0.4866\n",
      "Epoch 109/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7904 - loss: 0.4685\n",
      "Epoch 110/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7514 - loss: 0.4914\n",
      "Epoch 111/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7817 - loss: 0.4754\n",
      "Epoch 112/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7634 - loss: 0.4875\n",
      "Epoch 113/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7613 - loss: 0.4946\n",
      "Epoch 114/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7340 - loss: 0.5109\n",
      "Epoch 115/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7358 - loss: 0.5078\n",
      "Epoch 116/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7846 - loss: 0.4669\n",
      "Epoch 117/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7727 - loss: 0.4972\n",
      "Epoch 118/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7416 - loss: 0.4980\n",
      "Epoch 119/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7824 - loss: 0.4643\n",
      "Epoch 120/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7571 - loss: 0.4961\n",
      "Epoch 121/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7122 - loss: 0.5512\n",
      "Epoch 122/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7506 - loss: 0.4920\n",
      "Epoch 123/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7914 - loss: 0.4563\n",
      "Epoch 124/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7674 - loss: 0.4699\n",
      "Epoch 125/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7870 - loss: 0.4376\n",
      "Epoch 126/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7729 - loss: 0.4773\n",
      "Epoch 127/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7570 - loss: 0.5074\n",
      "Epoch 128/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7668 - loss: 0.4826\n",
      "Epoch 129/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7684 - loss: 0.4884\n",
      "Epoch 130/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7727 - loss: 0.4682\n",
      "Epoch 131/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7822 - loss: 0.4854\n",
      "Epoch 132/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7645 - loss: 0.5055\n",
      "Epoch 133/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7676 - loss: 0.4903\n",
      "Epoch 134/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7888 - loss: 0.4577\n",
      "Epoch 135/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7761 - loss: 0.4862\n",
      "Epoch 136/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7941 - loss: 0.4658\n",
      "Epoch 137/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7700 - loss: 0.4743\n",
      "Epoch 138/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7862 - loss: 0.4485\n",
      "Epoch 139/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7580 - loss: 0.4757\n",
      "Epoch 140/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7594 - loss: 0.5041\n",
      "Epoch 141/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7736 - loss: 0.4851\n",
      "Epoch 142/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7636 - loss: 0.4890\n",
      "Epoch 143/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7508 - loss: 0.4960\n",
      "Epoch 144/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7666 - loss: 0.4635\n",
      "Epoch 145/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7847 - loss: 0.4667\n",
      "Epoch 146/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7613 - loss: 0.4811\n",
      "Epoch 147/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7771 - loss: 0.4570\n",
      "Epoch 148/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7655 - loss: 0.4763\n",
      "Epoch 149/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7339 - loss: 0.5001\n",
      "Epoch 150/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7759 - loss: 0.4751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f12cbc6c850>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6373 - loss: 2.0308\n",
      "Epoch 2/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6100 - loss: 0.8125\n",
      "Epoch 3/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6425 - loss: 0.7449\n",
      "Epoch 4/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6351 - loss: 0.7085\n",
      "Epoch 5/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6832 - loss: 0.6639\n",
      "Epoch 6/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6352 - loss: 0.6701\n",
      "Epoch 7/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6668 - loss: 0.6629\n",
      "Epoch 8/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6676 - loss: 0.6407\n",
      "Epoch 9/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6936 - loss: 0.6270\n",
      "Epoch 10/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6778 - loss: 0.6280\n",
      "Epoch 11/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7059 - loss: 0.6245\n",
      "Epoch 12/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7094 - loss: 0.6193\n",
      "Epoch 13/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7008 - loss: 0.6061\n",
      "Epoch 14/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6713 - loss: 0.6270\n",
      "Epoch 15/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6967 - loss: 0.6150\n",
      "Epoch 16/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6896 - loss: 0.6056\n",
      "Epoch 17/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6972 - loss: 0.6147\n",
      "Epoch 18/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7037 - loss: 0.6116\n",
      "Epoch 19/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7030 - loss: 0.5975\n",
      "Epoch 20/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7177 - loss: 0.5938\n",
      "Epoch 21/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6908 - loss: 0.6013\n",
      "Epoch 22/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7320 - loss: 0.5755\n",
      "Epoch 23/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6806 - loss: 0.6094\n",
      "Epoch 24/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6981 - loss: 0.5816\n",
      "Epoch 25/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6779 - loss: 0.5964\n",
      "Epoch 26/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7091 - loss: 0.5780\n",
      "Epoch 27/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6863 - loss: 0.6050\n",
      "Epoch 28/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7115 - loss: 0.5871\n",
      "Epoch 29/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7341 - loss: 0.5657\n",
      "Epoch 30/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7038 - loss: 0.5762\n",
      "Epoch 31/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7030 - loss: 0.5593\n",
      "Epoch 32/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7383 - loss: 0.5583\n",
      "Epoch 33/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7091 - loss: 0.5712\n",
      "Epoch 34/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7255 - loss: 0.5486\n",
      "Epoch 35/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7079 - loss: 0.5524\n",
      "Epoch 36/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7160 - loss: 0.5537\n",
      "Epoch 37/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7218 - loss: 0.5528\n",
      "Epoch 38/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7421 - loss: 0.5425\n",
      "Epoch 39/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7306 - loss: 0.5388\n",
      "Epoch 40/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7201 - loss: 0.5484\n",
      "Epoch 41/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7086 - loss: 0.5689\n",
      "Epoch 42/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7300 - loss: 0.5438\n",
      "Epoch 43/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7244 - loss: 0.5487\n",
      "Epoch 44/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7413 - loss: 0.5229\n",
      "Epoch 45/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7170 - loss: 0.5357\n",
      "Epoch 46/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7232 - loss: 0.5357\n",
      "Epoch 47/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7290 - loss: 0.5423\n",
      "Epoch 48/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7227 - loss: 0.5450\n",
      "Epoch 49/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7587 - loss: 0.5223\n",
      "Epoch 50/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7405 - loss: 0.5656\n",
      "Epoch 51/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7514 - loss: 0.5368\n",
      "Epoch 52/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7473 - loss: 0.5319\n",
      "Epoch 53/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7273 - loss: 0.5498\n",
      "Epoch 54/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7009 - loss: 0.5788\n",
      "Epoch 55/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7525 - loss: 0.5220\n",
      "Epoch 56/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7340 - loss: 0.5472\n",
      "Epoch 57/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7484 - loss: 0.5376\n",
      "Epoch 58/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7311 - loss: 0.5257\n",
      "Epoch 59/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7170 - loss: 0.5349\n",
      "Epoch 60/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7377 - loss: 0.5379\n",
      "Epoch 61/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7366 - loss: 0.5288\n",
      "Epoch 62/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7573 - loss: 0.4938\n",
      "Epoch 63/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7513 - loss: 0.5130\n",
      "Epoch 64/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7382 - loss: 0.5260\n",
      "Epoch 65/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7383 - loss: 0.5502\n",
      "Epoch 66/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7466 - loss: 0.5308\n",
      "Epoch 67/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7187 - loss: 0.5357\n",
      "Epoch 68/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7259 - loss: 0.5382\n",
      "Epoch 69/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7389 - loss: 0.5256\n",
      "Epoch 70/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7491 - loss: 0.5168\n",
      "Epoch 71/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7416 - loss: 0.5241\n",
      "Epoch 72/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7471 - loss: 0.5252\n",
      "Epoch 73/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7245 - loss: 0.5476\n",
      "Epoch 74/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7475 - loss: 0.5156\n",
      "Epoch 75/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7084 - loss: 0.5522\n",
      "Epoch 76/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7009 - loss: 0.5531\n",
      "Epoch 77/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7544 - loss: 0.5163\n",
      "Epoch 78/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7711 - loss: 0.5168\n",
      "Epoch 79/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7448 - loss: 0.5316\n",
      "Epoch 80/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7496 - loss: 0.5254\n",
      "Epoch 81/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7556 - loss: 0.5237\n",
      "Epoch 82/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7496 - loss: 0.5072\n",
      "Epoch 83/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7609 - loss: 0.5076\n",
      "Epoch 84/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7508 - loss: 0.5143\n",
      "Epoch 85/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7797 - loss: 0.4849\n",
      "Epoch 86/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7863 - loss: 0.4814\n",
      "Epoch 87/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7454 - loss: 0.5203\n",
      "Epoch 88/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7366 - loss: 0.5232\n",
      "Epoch 89/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7549 - loss: 0.5172\n",
      "Epoch 90/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7122 - loss: 0.5553\n",
      "Epoch 91/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7343 - loss: 0.5107\n",
      "Epoch 92/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7536 - loss: 0.5138\n",
      "Epoch 93/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7496 - loss: 0.5103\n",
      "Epoch 94/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7520 - loss: 0.5039\n",
      "Epoch 95/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7736 - loss: 0.4896\n",
      "Epoch 96/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7599 - loss: 0.4971\n",
      "Epoch 97/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7588 - loss: 0.5199\n",
      "Epoch 98/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7626 - loss: 0.4902\n",
      "Epoch 99/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7804 - loss: 0.4806\n",
      "Epoch 100/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7688 - loss: 0.5056\n",
      "Epoch 101/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7556 - loss: 0.5350\n",
      "Epoch 102/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7665 - loss: 0.5106\n",
      "Epoch 103/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7457 - loss: 0.4945\n",
      "Epoch 104/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7532 - loss: 0.5189\n",
      "Epoch 105/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7298 - loss: 0.5168\n",
      "Epoch 106/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7658 - loss: 0.4732\n",
      "Epoch 107/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7365 - loss: 0.5305\n",
      "Epoch 108/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7689 - loss: 0.4857\n",
      "Epoch 109/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7655 - loss: 0.4981\n",
      "Epoch 110/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7549 - loss: 0.5174\n",
      "Epoch 111/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7612 - loss: 0.5058\n",
      "Epoch 112/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7572 - loss: 0.4976\n",
      "Epoch 113/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7578 - loss: 0.4949\n",
      "Epoch 114/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7340 - loss: 0.5294\n",
      "Epoch 115/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7467 - loss: 0.5212\n",
      "Epoch 116/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7521 - loss: 0.5098\n",
      "Epoch 117/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7747 - loss: 0.4989\n",
      "Epoch 118/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7898 - loss: 0.4602\n",
      "Epoch 119/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7445 - loss: 0.5210\n",
      "Epoch 120/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.5032\n",
      "Epoch 121/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7620 - loss: 0.5015\n",
      "Epoch 122/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7548 - loss: 0.4995\n",
      "Epoch 123/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7681 - loss: 0.4813\n",
      "Epoch 124/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7630 - loss: 0.5056\n",
      "Epoch 125/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7601 - loss: 0.4940\n",
      "Epoch 126/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7618 - loss: 0.4905\n",
      "Epoch 127/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7647 - loss: 0.4916\n",
      "Epoch 128/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7701 - loss: 0.4802\n",
      "Epoch 129/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7746 - loss: 0.4980\n",
      "Epoch 130/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7378 - loss: 0.4963\n",
      "Epoch 131/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7727 - loss: 0.4958\n",
      "Epoch 132/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7434 - loss: 0.5071\n",
      "Epoch 133/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7449 - loss: 0.5258\n",
      "Epoch 134/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7406 - loss: 0.5116\n",
      "Epoch 135/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7639 - loss: 0.4997\n",
      "Epoch 136/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7787 - loss: 0.4901\n",
      "Epoch 137/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7750 - loss: 0.4806\n",
      "Epoch 138/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7711 - loss: 0.4919\n",
      "Epoch 139/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7650 - loss: 0.4937\n",
      "Epoch 140/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7691 - loss: 0.4962\n",
      "Epoch 141/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7706 - loss: 0.4771\n",
      "Epoch 142/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7500 - loss: 0.5223\n",
      "Epoch 143/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7493 - loss: 0.4936\n",
      "Epoch 144/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7738 - loss: 0.4734\n",
      "Epoch 145/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7372 - loss: 0.5308\n",
      "Epoch 146/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7693 - loss: 0.5051\n",
      "Epoch 147/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7774 - loss: 0.4847\n",
      "Epoch 148/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7678 - loss: 0.4960\n",
      "Epoch 149/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7522 - loss: 0.4971\n",
      "Epoch 150/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7743 - loss: 0.4754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f12cbde85d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7436 - loss: 0.5061\n",
      "\n",
      "compile_metrics: 77.34%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)  \n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7483 - loss: 0.5156\n",
      "\n",
      "compile_metrics: 76.82%\n"
     ]
    }
   ],
   "source": [
    "scores = model2.evaluate(X, Y)  \n",
    "print(\"\\n%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizamos predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "[1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicciones \n",
    "predictions = model.predict(X)  \n",
    "rounded = [round(x[0]) for x in predictions]  \n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "[1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicciones \n",
    "predictions = model2.predict(X)  \n",
    "rounded = [round(x[0]) for x in predictions]  \n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de una Red Neuronal Sencilla con PYTORCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyTorch** es una librería de Python para deep learning creada y publicada por Facebook.\n",
    "Además de PyTorch, también existe la librería *torchvision* que se utiliza habitualmente junto con PyTorch. Proporciona multitud de funciones útiles para proyectos de visión por computador.   \n",
    "Para instalar Pytorch sistema, a través de *pip*, ejecutaremos la siguiente instrucción:   \n",
    "\n",
    "***pip install torch torchvision***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('./datasets/pima-indians-diabetes.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la arquitectura de la RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(          # Sequential es una pila de capas\n",
    "    nn.Linear(8, 12),           # Capa lineal de 8 neuronas a 12. Equivalente a la capa Dense de Keras\n",
    "    nn.ReLU(),                  # Función de activación ReLU\n",
    "    nn.Linear(12, 8),           # Capa lineal de 12 neuronas a 8\n",
    "    nn.ReLU(),                  # Función de activación ReLU\n",
    "    nn.Linear(8, 1),            # Capa lineal de 8 neuronas a 1\n",
    "    nn.Sigmoid()                # Función de activación Sigmoid. Se usa esta función de activación porque es un problema de clasificación binaria.\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = nn.BCELoss() # binary cross-entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bucle de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 0.7068017721176147\n",
      "Finished epoch 1, latest loss 0.6671782732009888\n",
      "Finished epoch 2, latest loss 0.6285037994384766\n",
      "Finished epoch 3, latest loss 0.5051481127738953\n",
      "Finished epoch 4, latest loss 0.44009003043174744\n",
      "Finished epoch 5, latest loss 0.42446666955947876\n",
      "Finished epoch 6, latest loss 0.4138326048851013\n",
      "Finished epoch 7, latest loss 0.4182598292827606\n",
      "Finished epoch 8, latest loss 0.4204920530319214\n",
      "Finished epoch 9, latest loss 0.4231330454349518\n",
      "Finished epoch 10, latest loss 0.4283069968223572\n",
      "Finished epoch 11, latest loss 0.42816847562789917\n",
      "Finished epoch 12, latest loss 0.4305548369884491\n",
      "Finished epoch 13, latest loss 0.43215084075927734\n",
      "Finished epoch 14, latest loss 0.4347168505191803\n",
      "Finished epoch 15, latest loss 0.43377256393432617\n",
      "Finished epoch 16, latest loss 0.4366224706172943\n",
      "Finished epoch 17, latest loss 0.43814677000045776\n",
      "Finished epoch 18, latest loss 0.4346116781234741\n",
      "Finished epoch 19, latest loss 0.4348903000354767\n",
      "Finished epoch 20, latest loss 0.44219374656677246\n",
      "Finished epoch 21, latest loss 0.4355584681034088\n",
      "Finished epoch 22, latest loss 0.443070650100708\n",
      "Finished epoch 23, latest loss 0.448390930891037\n",
      "Finished epoch 24, latest loss 0.45770376920700073\n",
      "Finished epoch 25, latest loss 0.4530819356441498\n",
      "Finished epoch 26, latest loss 0.43976926803588867\n",
      "Finished epoch 27, latest loss 0.4347170889377594\n",
      "Finished epoch 28, latest loss 0.427793949842453\n",
      "Finished epoch 29, latest loss 0.4247245490550995\n",
      "Finished epoch 30, latest loss 0.4327159523963928\n",
      "Finished epoch 31, latest loss 0.4374062418937683\n",
      "Finished epoch 32, latest loss 0.42865005135536194\n",
      "Finished epoch 33, latest loss 0.4258268475532532\n",
      "Finished epoch 34, latest loss 0.4196551740169525\n",
      "Finished epoch 35, latest loss 0.42320436239242554\n",
      "Finished epoch 36, latest loss 0.4233154058456421\n",
      "Finished epoch 37, latest loss 0.4214443564414978\n",
      "Finished epoch 38, latest loss 0.41973063349723816\n",
      "Finished epoch 39, latest loss 0.41701894998550415\n",
      "Finished epoch 40, latest loss 0.41504913568496704\n",
      "Finished epoch 41, latest loss 0.41297218203544617\n",
      "Finished epoch 42, latest loss 0.4063013195991516\n",
      "Finished epoch 43, latest loss 0.4153752028942108\n",
      "Finished epoch 44, latest loss 0.41805970668792725\n",
      "Finished epoch 45, latest loss 0.4078342020511627\n",
      "Finished epoch 46, latest loss 0.40417617559432983\n",
      "Finished epoch 47, latest loss 0.4048265516757965\n",
      "Finished epoch 48, latest loss 0.4004572927951813\n",
      "Finished epoch 49, latest loss 0.4044976830482483\n",
      "Finished epoch 50, latest loss 0.39882928133010864\n",
      "Finished epoch 51, latest loss 0.40881112217903137\n",
      "Finished epoch 52, latest loss 0.4101111590862274\n",
      "Finished epoch 53, latest loss 0.4071478545665741\n",
      "Finished epoch 54, latest loss 0.4063926339149475\n",
      "Finished epoch 55, latest loss 0.4139123260974884\n",
      "Finished epoch 56, latest loss 0.40516147017478943\n",
      "Finished epoch 57, latest loss 0.40767180919647217\n",
      "Finished epoch 58, latest loss 0.40971729159355164\n",
      "Finished epoch 59, latest loss 0.4135614037513733\n",
      "Finished epoch 60, latest loss 0.41155382990837097\n",
      "Finished epoch 61, latest loss 0.4121861159801483\n",
      "Finished epoch 62, latest loss 0.41305285692214966\n",
      "Finished epoch 63, latest loss 0.4112034738063812\n",
      "Finished epoch 64, latest loss 0.4021073877811432\n",
      "Finished epoch 65, latest loss 0.4066188931465149\n",
      "Finished epoch 66, latest loss 0.40499621629714966\n",
      "Finished epoch 67, latest loss 0.40015578269958496\n",
      "Finished epoch 68, latest loss 0.4039420187473297\n",
      "Finished epoch 69, latest loss 0.39834991097450256\n",
      "Finished epoch 70, latest loss 0.3967902362346649\n",
      "Finished epoch 71, latest loss 0.3997994661331177\n",
      "Finished epoch 72, latest loss 0.396060973405838\n",
      "Finished epoch 73, latest loss 0.39853429794311523\n",
      "Finished epoch 74, latest loss 0.4027911424636841\n",
      "Finished epoch 75, latest loss 0.40011927485466003\n",
      "Finished epoch 76, latest loss 0.4032959043979645\n",
      "Finished epoch 77, latest loss 0.39995503425598145\n",
      "Finished epoch 78, latest loss 0.3991236388683319\n",
      "Finished epoch 79, latest loss 0.40131843090057373\n",
      "Finished epoch 80, latest loss 0.3963598310947418\n",
      "Finished epoch 81, latest loss 0.40418022871017456\n",
      "Finished epoch 82, latest loss 0.3989614248275757\n",
      "Finished epoch 83, latest loss 0.400879442691803\n",
      "Finished epoch 84, latest loss 0.39912936091423035\n",
      "Finished epoch 85, latest loss 0.40152716636657715\n",
      "Finished epoch 86, latest loss 0.3989935517311096\n",
      "Finished epoch 87, latest loss 0.3919650912284851\n",
      "Finished epoch 88, latest loss 0.4007006287574768\n",
      "Finished epoch 89, latest loss 0.39410629868507385\n",
      "Finished epoch 90, latest loss 0.3974423110485077\n",
      "Finished epoch 91, latest loss 0.4015883803367615\n",
      "Finished epoch 92, latest loss 0.4039815068244934\n",
      "Finished epoch 93, latest loss 0.39712783694267273\n",
      "Finished epoch 94, latest loss 0.40060660243034363\n",
      "Finished epoch 95, latest loss 0.3945907652378082\n",
      "Finished epoch 96, latest loss 0.4034471809864044\n",
      "Finished epoch 97, latest loss 0.3924272358417511\n",
      "Finished epoch 98, latest loss 0.3989937901496887\n",
      "Finished epoch 99, latest loss 0.39244768023490906\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "for epoch in range(n_epochs):               # bucle de entrenamiento en base al número de épocas\n",
    "    for i in range(0, len(X), batch_size):  # bucle de entrenamiento en base al tamaño del batch\n",
    "        Xbatch = X[i:i+batch_size]          # seleccionamos el batch\n",
    "        y_pred = model(Xbatch)              # hacemos la predicción\n",
    "        ybatch = y[i:i+batch_size]          # seleccionamos las etiquetas\n",
    "        loss = loss_fn(y_pred, ybatch)      # calculamos la pérdida\n",
    "        optimizer.zero_grad()               # ponemos a cero los gradientes\n",
    "        loss.backward()                     # retropropagamos\n",
    "        optimizer.step()                    # actualizamos los pesos\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencia (predicción)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  5.0000, 116.0000,  74.0000,   0.0000,   0.0000,  25.6000,   0.2010,\n",
      "         30.0000]) -> tensor([0.2945])\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "X_sample = X[i:i+1]             # seleccionamos una muestra\n",
    "model.eval()                    # ponemos el modelo en modo evaluación\n",
    "with torch.no_grad():           # deshabilitamos el cálculo de gradientes\n",
    "    y_pred = model(X_sample)    # hacemos la predicción\n",
    "print(f\"{X_sample[0]} -> {y_pred[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Algunos modelos se comportarán de forma diferente entre el entrenamiento y la inferencia. \n",
    "- La línea de **model.eval()** es para señalar al modelo que la intención es ejecutar el modelo para la inferencia. \n",
    "- La línea de **torch.no_grad()** es para crear un contexto para ejecutar el modelo, de tal forma que PyTorch sepa que calcular el gradiente no es necesario. Esto puede consumir menos recursos.   \n",
    "\n",
    "Así es también como se puede evaluar el modelo. El modelo produce un valor sigmoide, que está entre 0 y 1. Se puede interpretar el valor redondeando este al entero más cercano (es decir, la etiqueta booleana). Comparando la frecuencia con la que la predicción tras el redondeo coincide con el objetivo, se puede asignar un porcentaje de precisión al modelo, como se ve a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()                # ponemos el modelo en modo evaluación\n",
    "with torch.no_grad():       # deshabilitamos el cálculo de gradientes\n",
    "    y_pred = model(X)       # hacemos la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7395833134651184\n"
     ]
    }
   ],
   "source": [
    "accuracy = (y_pred.round() == y).float().mean() # Se redondea y_pred para que sea un valor 0 o 1\n",
    "print(f\"Accuracy:  {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
