{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIDAD DE TRABAJO 1.    \n",
    "## APTDO. 1.2.4.1 - REDES NEURONALES PREENTRENADAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJEMPLO 1 - Transfer Learning con RESNET50 + TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 18:04:46.346024: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ 1. Cargar el modelo ResNet50 preentrenado (sin la capa de salida)\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ 2. Congelar las capas del modelo base (Feature Extraction) \n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ 3. Construir un nuevo modelo agregando capas personalizadas\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),  \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),  \n",
    "    Dense(2, activation='softmax')  # 2 clases: Gato o Perro\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ 4. Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ 5. Preparar los datos con ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"datasets/perros_gatos/\",  # ğŸ“Œ Ruta de imÃ¡genes (organizadas en carpetas por clases)\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = train_datagen.flow_from_directory(\n",
    "    \"datasets/perros_gatos/\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.5608 - loss: 8.2171 - val_accuracy: 0.5700 - val_loss: 0.7947\n",
      "Epoch 2/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.4850 - loss: 0.9232 - val_accuracy: 0.5100 - val_loss: 0.7046\n",
      "Epoch 3/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.5166 - loss: 0.6892 - val_accuracy: 0.6150 - val_loss: 0.6882\n",
      "Epoch 4/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.5538 - loss: 0.7156 - val_accuracy: 0.7050 - val_loss: 0.6912\n",
      "Epoch 5/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.5648 - loss: 0.6712 - val_accuracy: 0.6050 - val_loss: 0.6892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2b6c268950>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ğŸ“Œ 6. Entrenar el modelo con Transfer Learning\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6255 - loss: 0.7228\n",
      "PrecisiÃ³n en validaciÃ³n: 0.61\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ 7. Evaluar el modelo en datos de validaciÃ³n\n",
    "loss, acc = model.evaluate(val_generator)\n",
    "print(f\"PrecisiÃ³n en validaciÃ³n: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExplicaciÃ³n del cÃ³digo   \n",
    "\n",
    "- Cargamos ResNet50 sin la Ãºltima capa (include_top=False) para usarlo como extractor de caracterÃ­sticas.  \n",
    "- Congelamos sus capas (base_model.trainable = False) para que no se ajusten en el nuevo entrenamiento.\n",
    "- Agregamos nuevas capas personalizadas, adaptadas a la nueva tarea de clasificaciÃ³n (2 clases).\n",
    "- Compilamos y entrenamos el modelo solo con las nuevas capas.\n",
    "- Usamos ImageDataGenerator para cargar imÃ¡genes desde carpetas y aplicar preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJEMPLO 2 - Transfer Learning con Hugging Face - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos librerÃ­as   \n",
    "- **transformers** es una biblioteca de Hugging Face que permite utilizar modelos preentrenados de Procesamiento del Lenguaje Natural (PLN) como BERT, GPT-3, T5, DistilBERT, entre otros.\n",
    "- **pipeline** es una funciÃ³n de alto nivel que facilita el uso de estos modelos sin necesidad de cargar manualmente los pesos y configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tf-keras\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CreaciÃ³n de modelo preentrenado para anÃ¡lisis de sentimiento   \n",
    "- Se instancia un pipeline de anÃ¡lisis de sentimiento utilizando un modelo preentrenado por defecto de Hugging Face.\n",
    "- Si es la primera vez que ejecutas este cÃ³digo, el modelo se descargarÃ¡ automÃ¡ticamente desde los servidores de Hugging Face.\n",
    "- Se carga un modelo es multilingÃ¼e y puede procesar textos en espaÃ±ol. Es el modelo <a href=\"https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment?utm_source=chatgpt.com\"> ***bert-base-multilingual-uncased-sentiment*** </a>desarrollado por NLP Town. Este modelo estÃ¡ basado en la arquitectura BERT y ha sido ajustado especÃ­ficamente para el anÃ¡lisis de sentimientos en reseÃ±as de productos en seis idiomas: inglÃ©s, neerlandÃ©s, alemÃ¡n, francÃ©s, espaÃ±ol e italiano. Sus caracterÃ­sticas principales son:\n",
    "\n",
    "  - Arquitectura: Basado en BERT-base-multilingual-uncased, una versiÃ³n de BERT que maneja mÃºltiples idiomas y no distingue entre mayÃºsculas y minÃºsculas.\n",
    "\n",
    "  - Tarea: ClasificaciÃ³n de sentimientos en reseÃ±as de productos, prediciendo una puntuaciÃ³n en una escala de 1 a 5 estrellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelo preentrenado para anÃ¡lisis de sentimiento\n",
    "# analisis_sentimiento = pipeline(\"sentiment-analysis\")\n",
    "analisis_sentimiento = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizar anÃ¡lisis sobre textos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '5 stars', 'score': 0.7860149145126343}]\n"
     ]
    }
   ],
   "source": [
    "# Probar con un texto\n",
    "# resultado = analisis_sentimiento(\"This course is very interesting.\")\n",
    "resultado = analisis_sentimiento(\"Este curso es increÃ­ble y muy Ãºtil.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '5 stars', 'score': 0.7707265615463257}, {'label': '2 stars', 'score': 0.5164674520492554}, {'label': '4 stars', 'score': 0.5573275089263916}]\n"
     ]
    }
   ],
   "source": [
    "# Analizar varios textos\n",
    "textos = [\"Me encanta este curso.\", \"No me gusta la interfaz de usuario.\", \"Estoy satisfecho con el resultado.\"]\n",
    "resultados = analisis_sentimiento(textos)\n",
    "print(resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
