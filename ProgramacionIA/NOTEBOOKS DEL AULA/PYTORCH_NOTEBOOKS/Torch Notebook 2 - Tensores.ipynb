{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tensores con Pytorch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5758683ba5855fbf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uno de los conceptos más frecuentes en machine learning es el de **tensor**.   \n",
    "Un tensor es la generalización del concepto de vector utilizando el rango para definir el número de índices del tensor. Por ejemplo, un vector es un tensor de rango 1, una matriz es un tensor de rango 2 y un tensor de rango tres sería una matriz con un eje extra.    \n",
    "La clase **torch.tensor** de PyTorch pemite trabajar cómodamente con tensores, tanto en la CPU como en la GPU. Existen diferentes formas de crear un tensor."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15ff095d5da77767"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 1:\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "Tensor 2:\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "\n",
      "Tensor 3:\n",
      "tensor([1, 2, 3, 4])\n",
      "\n",
      "Tensor 4:\n",
      "tensor([[0.7711, 0.5063, 0.8099],\n",
      "        [0.6221, 0.2899, 0.0663]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#A partir de una lista de Python\n",
    "list = ([1,2],[3,4],[5,6])\n",
    "tensor1=torch.tensor(list)\n",
    "print(\"Tensor 1:\")\n",
    "print(tensor1)\n",
    "print()\n",
    "\n",
    "#A partir de los datos directamente\n",
    "tensor2=torch.tensor([[[1, 2, 3],[4, 5, 6]],[[1, 2, 3],[4, 5, 6]]])\n",
    "print(\"Tensor 2:\")\n",
    "print(tensor2)\n",
    "print()\n",
    "\n",
    "#A partir de un array numpy\n",
    "tensor3=torch.tensor(np.array([1,2,3,4]))\n",
    "print(\"Tensor 3:\")\n",
    "print(tensor3)\n",
    "print()\n",
    "\n",
    "#Usando una operación de creación de tensores\n",
    "tensor4=torch.rand(2,3)\n",
    "print(\"Tensor 4:\")\n",
    "print(tensor4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T17:47:09.594839Z",
     "start_time": "2024-11-03T17:47:09.579174Z"
    }
   },
   "id": "4898fc8df83fdd4d",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T17:47:48.879748Z",
     "start_time": "2024-11-03T17:47:48.865361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#A través del método size se obtiene el tamaño del tensor, su rango y las dimensiones\n",
    "\n",
    "#Un tensor de rango 2 (3,2) para tensor1\n",
    "print(tensor1.size())\n",
    "\n",
    "#Un tensor de rango 3 con las dimensiones (2,2,3) para tensor2\n",
    "print(tensor2.size())"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor(2)\n",
      "torch.Size([2, 4])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "#A los componentes de los tensores se puede acceder como usualmente se efectua en Python\n",
    "print(tensor1[0])\n",
    "print(tensor1[0,1])\n",
    "\n",
    "#Con view se cambia las dimensiones y el rango del tensor\n",
    "tensor5=torch.rand(2,4)\n",
    "print(tensor5.size())\n",
    "\n",
    "tensor6=tensor5.view(8)\n",
    "print(tensor6.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T17:48:43.768263Z",
     "start_time": "2024-11-03T17:48:43.763444Z"
    }
   },
   "id": "a6cfc0e382c76537",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([12.])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Un tensor se puede crear con requires_grad=True para que torch.autograd registre las operaciones y realice la diferenciación automática\n",
    "\n",
    "x = torch.tensor([2],dtype=torch.float,requires_grad=True)\n",
    "y = x.pow(3)\n",
    "y.backward()\n",
    "x.grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T17:49:19.732885Z",
     "start_time": "2024-11-03T17:49:19.701441Z"
    }
   },
   "id": "4217e877bad2b04c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#PyTorch permite trabajar con CUDA para realizar las operaciones en la GPU\u001B[39;00m\n\u001B[0;32m      2\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available()\n\u001B[1;32m----> 3\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mget_device_name(\u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[1;32m~\\PycharmProjects\\PytorchBasics\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:940\u001B[0m, in \u001B[0;36mcurrent_device\u001B[1;34m()\u001B[0m\n\u001B[0;32m    938\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcurrent_device\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mint\u001B[39m:\n\u001B[0;32m    939\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 940\u001B[0m     \u001B[43m_lazy_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    941\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_cuda_getDevice()\n",
      "File \u001B[1;32m~\\PycharmProjects\\PytorchBasics\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    306\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    308\u001B[0m     )\n\u001B[0;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    313\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    314\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "#PyTorch permite trabajar con CUDA para realizar las operaciones en la GPU\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.current_device()\n",
    "print(torch.cuda.get_device_name(0))\n",
    "# Se produce un error si no se dispone de GPU instalada y configurada en el sistema."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T17:50:37.365880Z",
     "start_time": "2024-11-03T17:50:37.192981Z"
    }
   },
   "id": "f8363927c9dc2e69",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "#Comparación del tiempo en realizar una multiplicaión de matrices en la CPU y en la GPU\n",
    "%%time\n",
    "for i in range(500):\n",
    "  x = torch.randn(1000,1000)\n",
    "  y = torch.randn(1000,1000)\n",
    "  z = torch.matmul(x,y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T17:51:37.280213Z",
     "start_time": "2024-11-03T17:51:37.276434Z"
    }
   },
   "id": "357ea1c10fe8121c",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "#Se realiza la multiplicación en la GPU\n",
    "%%time\n",
    "cuda0 = torch.device('cuda:0')\n",
    "for i in range(500):\n",
    "  x = torch.randn(1000,1000,device = cuda0)\n",
    "  y = torch.randn(1000,1000,device =cuda0)\n",
    "  z = torch.matmul(x,y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T17:52:36.771760Z",
     "start_time": "2024-11-03T17:52:36.767986Z"
    }
   },
   "id": "173c0936b79e12b7",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Almacenamiento de tensores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bf6f63174b88fc4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como hemos visto, los tensores son un elemento básico en PyTorch. Son los elementos de diferente rango (escalares, vectores, matrices, etc.) que contienen la información en PyTorch y sobre los que actúan los modelos.\n",
    "\n",
    "Sin embargo, a pesar de su rango y dimensiones, los tensores se almacenan en memoria en un array unidimensional de elementos contiguos. De esta forma se homogeiniza su almacenamiento y se hace más eficiente su tratamient\n",
    "\n",
    "A esta información se accede a través de la clase Torch.storage(). A continuación, vemos un ejemplo de un tensor y su almacenamiento en un array unidimensional.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d2ef7b21254a9c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordi\\AppData\\Local\\Temp\\ipykernel_5632\\3283328093.py:4: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  tensor1.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": " 2.0\n 1.0\n 4.0\n 3.0\n 2.0\n 1.0\n[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "tensor1 = torch.tensor([[2.0, 1.0], [4.0, 3.0], [2.0, 1.0]])\n",
    "tensor1.storage()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T17:56:48.384793Z",
     "start_time": "2024-11-03T17:56:48.365871Z"
    }
   },
   "id": "b8bc6d425716fbcf",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los tensores son vistas de este almacenamiento y para poder relacionar las diferentes vistas con un único almacenamiento, PyTorch hace uso de los metadatos size, offset y stride.\n",
    "\n",
    "- *Size* es como shape en numpy e indica el número de elementos en cada dimensión. \n",
    "- *Offset* es el índice en el almacenamiento (storage) que indica donde está el primer elemento del tensor.\n",
    "- El *stride* es el número de desplazamientos en el almacenamiento necesarios para indexar el siguiente elemento en cada dimensión.\n",
    "\n",
    "A continuación, vemos estos metadatos para nuestro tensor."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1a55f55844112e3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño (size) es torch.Size([3, 2])\n",
      "El offset es 0\n",
      "El stride es (2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"El tamaño (size) es\", tensor1.size())\n",
    "\n",
    "print(\"El offset es\", tensor1.storage_offset())\n",
    "\n",
    "print(\"El stride es\", tensor1.stride())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T17:58:46.883904Z",
     "start_time": "2024-11-03T17:58:46.880165Z"
    }
   },
   "id": "b24008d1f9244fb8",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como se puede ver, nuestro tensor tiene un tamaño de 3 filas y dos columnas y el primer elemento del tensor está en la posición cero del almacenamiento.\n",
    "\n",
    "Para movernos una posición en la primera dimensión/segunda dimensión (fila/columna) necesitamos avanzar (2,1) posiciones en el almacenamiento.\n",
    "\n",
    "A continuación creamos otro tensor de 3 filas y 3 columnas y vemos como ahora para movernos en la primera dimensión (fila) necesitamos avanzar 3 posiciones en el almacenamiento."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a432b78f92d8d7a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño (size) es torch.Size([3, 3])\n",
      "El offset es 0\n",
      "El stride es (3, 1)\n"
     ]
    }
   ],
   "source": [
    "tensor2=torch.rand(3,3)\n",
    "\n",
    "print(\"El tamaño (size) es\", tensor2.size())\n",
    "\n",
    "print(\"El offset es\", tensor2.storage_offset())\n",
    "\n",
    "print(\"El stride es\", tensor2.stride())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:00:30.250253Z",
     "start_time": "2024-11-03T18:00:30.245287Z"
    }
   },
   "id": "407e3de31658cc8f",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Un tensor cuya vista coincida con el almacenamiento es un **tensor contiguo**. Es decir, sus valores se almacenan desde la dimensión más a la derecha hacia adelante. Esto es conveniente en términos de eficiencia porque podemos recorrer el tensor en orden sin hacer saltos en la memoria.\n",
    "\n",
    "Hay una serie de operaciones en PyTorch que no cambian el almacenamiento pero sí que cambian la vista y, en consecuencia, los metadatos de vista del tensor. Son las operaciones *narrow(), view(), expand()* y *transpose()*.\n",
    "\n",
    "Vamos a transponer nuestro primer vector y ver su storage y sus metadatos:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2971b418f3322bf7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4., 2.],\n",
      "        [1., 3., 1.]])\n",
      " 2.0\n",
      " 1.0\n",
      " 4.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n",
      "¿Es el tensor contiguo? False\n",
      "El tamaño (size) es torch.Size([2, 3])\n",
      "El offset es 0\n",
      "El stride es (1, 2)\n"
     ]
    }
   ],
   "source": [
    "tensor1_transpose=tensor1.transpose(0,1)\n",
    "print(tensor1_transpose)\n",
    "print(tensor1_transpose.storage())\n",
    "\n",
    "print(\"¿Es el tensor contiguo?\", tensor1_transpose.is_contiguous())\n",
    "\n",
    "print(\"El tamaño (size) es\", tensor1_transpose.size())\n",
    "\n",
    "print(\"El offset es\", tensor1_transpose.storage_offset())\n",
    "\n",
    "print(\"El stride es\", tensor1_transpose.stride())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:01:02.396087Z",
     "start_time": "2024-11-03T18:01:02.374725Z"
    }
   },
   "id": "d7d1319cf9803161",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como se puede observar, el almacenamiento interno del tensor transpuesto con dos filas y tres columnas no cambia pero sí que cambian los metadatos de vista. Ahora el tensor no es contiguo y el stride es (1,2), por lo que necesitamos avanzar (1,2) posiciones en el almacenamiento para avanzar una posición en la (fila/columna)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac785c2511ab64f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ebce139e28bc4a45"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
