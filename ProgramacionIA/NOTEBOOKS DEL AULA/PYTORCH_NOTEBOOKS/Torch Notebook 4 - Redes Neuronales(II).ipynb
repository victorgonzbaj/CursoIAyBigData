{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Redes Neuronales II - Flujo de creación de un modelo basado en RRNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd4ee0c3160f4106"
  },
  {
   "cell_type": "markdown",
   "source": [
    "En este notebook vamos a ver todo el proceso de creación y entrenamiento de una red neuronal: creación del modelo, procesamiento de la entrada a través del modelo, computar la pérdida y actualizar los parámetros del modelo usando descenso por gradiente en función de la pérdida.\n",
    "\n",
    "Primero, importamos las principales librerías, incluida **torch.autograd** para optimización, y, seguidamente, definimos los parámetros del model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ba8fea634d336e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:18:35.508565Z",
     "start_time": "2024-11-03T18:18:32.760498Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Definición de parámetros\n",
    "input_size    = 10\n",
    "output_size    = 1   \n",
    "hidden_size   = 50   \n",
    "train_size= 5000\n",
    "batch_size=10    \n",
    "num_epochs    = 10     \n",
    "learning_rate = 1e-3 \n",
    "random=0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:18:38.786337Z",
     "start_time": "2024-11-03T18:18:38.783356Z"
    }
   },
   "id": "529842cc972d9820",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos la secuencia de entrenamiento.  \n",
    "Calculamos el número de secuencias de tamaño batch_size que contendrá la secuencia de entrenamiento.   \n",
    "Creamos la secuencia de entrenamiento usando torch.normal y la salida, que en función del parámetro random, será una combinación lineal de la entrada o una salida aleatoria."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d76b6429d923c29f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len=int(train_size/batch_size)\n",
    "\n",
    "input=torch.normal(0, 1, size=(train_size, input_size))\n",
    "input=input/input.max()\n",
    "\n",
    "linear1=nn.Linear(input_size, output_size)\n",
    "\n",
    "if random==0:\n",
    "  with torch.no_grad():\n",
    "      label=linear1(input)\n",
    "else:\n",
    "      label=torch.normal(0, 1, size=(train_size, output_size))\n",
    "      label=label/label.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:19:30.505201Z",
     "start_time": "2024-11-03T18:19:30.487143Z"
    }
   },
   "id": "1ff55b05692bec17",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definimos el modelo, extendiendo la clase nn.Module. El modelo tiene una capa lineal, una ReLu y otra capa lineal, para poder hacer predicciones. Creamos una instancia del modelo con el tamaño la entrada, capas intermedias y salida indicados"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85780635c0fd7cab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
    "        self.relu1 = nn.ReLU()                          \n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) \n",
    "    \n",
    "    def forward(self, x):                              \n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = Net(input_size, hidden_size, output_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:20:04.112620Z",
     "start_time": "2024-11-03T18:20:04.107017Z"
    }
   },
   "id": "2402baef187022eb",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos a proceder con el entrenamiento del modelo. Creamos una instancia de la función de pérdidas torch.nn.L1Loss(), que calcula la desviación absoluta media entre dos tensores. Usamos el paquete torch.optim que implementa varios algoritmos de optimización, creando una instancia del algoritmo adam, especificando los parámetros a optimizar y la learning rate.\n",
    "\n",
    "Creamos el blucle de entrenamiento, donde para cada epoch (secuencia completa de entrenamiento), para cada batch de la entrada, borra los gradientes de los parámetros, selecciona la secuencia de entrada y salida, procesa la entrada con el modelo y la compara con la salida para calcular el error con loss = criterion(output, label1). Una vez calculado el error, se computa el gradiente de los parámetros con loss.backward() y se actualizan los parámetros usando este gradiente con optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0e98ece5b331368"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/500], Loss: 0.0817\n",
      "Epoch [1/10], Step [100/500], Loss: 0.0195\n",
      "Epoch [1/10], Step [200/500], Loss: 0.0125\n",
      "Epoch [1/10], Step [300/500], Loss: 0.0119\n",
      "Epoch [1/10], Step [400/500], Loss: 0.0120\n",
      "Epoch [1/10], Step [500/500], Loss: 0.0041\n",
      "Epoch [2/10], Step [1/500], Loss: 0.0060\n",
      "Epoch [2/10], Step [100/500], Loss: 0.0052\n",
      "Epoch [2/10], Step [200/500], Loss: 0.0047\n",
      "Epoch [2/10], Step [300/500], Loss: 0.0046\n",
      "Epoch [2/10], Step [400/500], Loss: 0.0051\n",
      "Epoch [2/10], Step [500/500], Loss: 0.0036\n",
      "Epoch [3/10], Step [1/500], Loss: 0.0031\n",
      "Epoch [3/10], Step [100/500], Loss: 0.0036\n",
      "Epoch [3/10], Step [200/500], Loss: 0.0035\n",
      "Epoch [3/10], Step [300/500], Loss: 0.0017\n",
      "Epoch [3/10], Step [400/500], Loss: 0.0054\n",
      "Epoch [3/10], Step [500/500], Loss: 0.0026\n",
      "Epoch [4/10], Step [1/500], Loss: 0.0021\n",
      "Epoch [4/10], Step [100/500], Loss: 0.0033\n",
      "Epoch [4/10], Step [200/500], Loss: 0.0031\n",
      "Epoch [4/10], Step [300/500], Loss: 0.0041\n",
      "Epoch [4/10], Step [400/500], Loss: 0.0029\n",
      "Epoch [4/10], Step [500/500], Loss: 0.0017\n",
      "Epoch [5/10], Step [1/500], Loss: 0.0022\n",
      "Epoch [5/10], Step [100/500], Loss: 0.0025\n",
      "Epoch [5/10], Step [200/500], Loss: 0.0020\n",
      "Epoch [5/10], Step [300/500], Loss: 0.0028\n",
      "Epoch [5/10], Step [400/500], Loss: 0.0025\n",
      "Epoch [5/10], Step [500/500], Loss: 0.0021\n",
      "Epoch [6/10], Step [1/500], Loss: 0.0011\n",
      "Epoch [6/10], Step [100/500], Loss: 0.0022\n",
      "Epoch [6/10], Step [200/500], Loss: 0.0019\n",
      "Epoch [6/10], Step [300/500], Loss: 0.0029\n",
      "Epoch [6/10], Step [400/500], Loss: 0.0020\n",
      "Epoch [6/10], Step [500/500], Loss: 0.0026\n",
      "Epoch [7/10], Step [1/500], Loss: 0.0026\n",
      "Epoch [7/10], Step [100/500], Loss: 0.0020\n",
      "Epoch [7/10], Step [200/500], Loss: 0.0010\n",
      "Epoch [7/10], Step [300/500], Loss: 0.0023\n",
      "Epoch [7/10], Step [400/500], Loss: 0.0025\n",
      "Epoch [7/10], Step [500/500], Loss: 0.0005\n",
      "Epoch [8/10], Step [1/500], Loss: 0.0009\n",
      "Epoch [8/10], Step [100/500], Loss: 0.0028\n",
      "Epoch [8/10], Step [200/500], Loss: 0.0026\n",
      "Epoch [8/10], Step [300/500], Loss: 0.0015\n",
      "Epoch [8/10], Step [400/500], Loss: 0.0013\n",
      "Epoch [8/10], Step [500/500], Loss: 0.0011\n",
      "Epoch [9/10], Step [1/500], Loss: 0.0013\n",
      "Epoch [9/10], Step [100/500], Loss: 0.0007\n",
      "Epoch [9/10], Step [200/500], Loss: 0.0016\n",
      "Epoch [9/10], Step [300/500], Loss: 0.0008\n",
      "Epoch [9/10], Step [400/500], Loss: 0.0017\n",
      "Epoch [9/10], Step [500/500], Loss: 0.0014\n",
      "Epoch [10/10], Step [1/500], Loss: 0.0015\n",
      "Epoch [10/10], Step [100/500], Loss: 0.0014\n",
      "Epoch [10/10], Step [200/500], Loss: 0.0013\n",
      "Epoch [10/10], Step [300/500], Loss: 0.0007\n",
      "Epoch [10/10], Step [400/500], Loss: 0.0016\n",
      "Epoch [10/10], Step [500/500], Loss: 0.0030\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len):      \n",
    "        optimizer.zero_grad()\n",
    "        input1=input[i*batch_size:(i+1)*batch_size]\n",
    "        label1=label[i*batch_size:(i+1)*batch_size]                             \n",
    "        output = net(input1)                             \n",
    "        loss = criterion(output, label1)                 \n",
    "        loss.backward()                                   \n",
    "        optimizer.step()                                  \n",
    "        \n",
    "        if (i==0) or ((i+1) % 100 == 0):                              \n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len, loss.data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:20:36.739568Z",
     "start_time": "2024-11-03T18:20:33.547809Z"
    }
   },
   "id": "31d06b13f4fc4369",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por último, a título ilustrativo, creamos una secuencia de entrada-salida, procesamos la entrada con el modelo y lo comparamos con la salida esperada."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d1c92a8e289158a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2591], grad_fn=<ViewBackward0>)\n",
      "tensor([0.2567], grad_fn=<ViewBackward0>)\n",
      "tensor(0.0025, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input11=torch.normal(0, 1, size=(10,))\n",
    "input11=input11/input11.max()\n",
    "label11=linear1(input11)\n",
    "print(label11)\n",
    "output11=net(input11)\n",
    "print(output11)\n",
    "print(criterion(output11, label11))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T18:21:23.815041Z",
     "start_time": "2024-11-03T18:21:23.810060Z"
    }
   },
   "id": "7b4f8f0a66024cce",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "77f06cf046d5317c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
