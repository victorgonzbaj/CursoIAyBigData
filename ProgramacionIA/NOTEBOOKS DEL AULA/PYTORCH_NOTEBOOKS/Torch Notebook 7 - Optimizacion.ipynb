{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMIZACIÓN BAYESIANA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con frecuencia en machine learning queremos optimizar los hiperparámetros de un modelo. Por ejemplo, en una red neuronal queremos saber el número de capas, el número de unidades por capa o la tasa de aprendizaje (learning rate) que logran un mejor comportamiento.\n",
    "\n",
    "Este problema lo podemos representar como:  \n",
    "\n",
    "$$ x_{m} = argmin_{x \\in {X}} f(x) $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, encontrar el conjunto de hiperparámetros $x_m$ que minimiza la función de coste.\n",
    "\n",
    "El problema es que las evaluaciones de la función de coste consumen muchos recursos, ya que en cada iteración hay que elegir unos hiperparámetros, entrenar el modelo con los datos de entrenamiento y calcular la función de coste.\n",
    "\n",
    "Se podrían usar soluciones como una buena estimación inicial, una búsqueda de cuadrículas (greed search) o una búsqueda aleatoria, pero no son eficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí surge la optimización bayesiana, que trata de construir uno modelo de probabilidad de la función de coste, selecciona los mejores hiperparámetros con este modelo y lo evalua con la función de coste original.\n",
    "\n",
    "Con este enfoque, se parte de una distribución inicial de los mejores hiperparámetros y se van seleccionando hiperparámetros para evaluarlos con la función objetivo y se actualiza el modelo de probabilidad. De esta forma se va actualizando el modelo P(éxito|hiperparámetros) que mapea el conjunto de hiperparámetros con una probabilidad de éxito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar de elegir los hiperparámetros del modelo de manera aleatoria, la optimización bayesiana los selecciona de una manera informada y va mejorando la selección con las evaluaciones realizadas. Los pasos que se siguen en la optimización bayesiana, que se pueden ver en detalle en este [enlace](https://gpss.cc/gpmc17/slides/LancasterMasterclass_1.pdf), son los siguientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Construir un modelo de probabilidad sustituto de la función objetivo/coste.\n",
    "- Encontrar los hiperparámetros que mejor se comportan según el modelo sustituto.\n",
    "- Aplicar dichos hiperparámetros y evaluarlos usando la función objetivo original.\n",
    "- Actualizar el modelo sustituto con los resultados de la evaluación.\n",
    "- Repetir los pasos dos a cuatro hasta que alcancemos un umbral de tiempo o de calidad.  \n",
    "\n",
    "\n",
    "Con el objetivo de facilitar el uso de la optimización bayesiana en Pytorch, [Facebook](https://ai.meta.com/blog/open-sourcing-ax-and-botorch-new-ai-tools-for-adaptive-experimentation/) ha puesto a disposición de la comunidad dos potentes herramientas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Ax](https://ax.dev/): Una herramienta de alto nivel para gestionar, desarrollar, desplegar y automatizar experimentos adaptativos.\n",
    "- [BoTorch](https://botorch.org/): Una librería de optimización bayesiana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ax proporciona librerías para interaccionar con BoTorch. BoTorch facilita la optimización bayesiana a través de una interfaz modular con primitivas de optimización, modelos de probabilidad sustitutos, funciones de adquisición y optimizadores. Todo ello aprovechando las ventajas de PyTorch como los grafos computacionales dinámicos y la diferenciación automática.\n",
    "\n",
    "El objetivo de estas librerías es facilitar a los usuarios el desarrollo, despliegue y optimización de algoritmos de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIMIZACIÓN BAYESIANA CON PYTORCH Y AX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un proceso de optimización bayesiana tendría los siguientes pasos (definidos a partir de este [tutorial](https://arxiv.org/abs/1807.02811)):\n",
    "\n",
    "- Definimos un proceso gaussiano previo (prior) para la función objetivo $f$.\n",
    "- Observamos $f$ en $n_0$ puntos iniciales y fijamos $n= n_0$.\n",
    "- Cuando $n ≤ N$:\n",
    "    - Se actualiza la distribución de probabilidad posterior de $f$ usando los datos disponibles.\n",
    "    - Se selecciona $x_n$ como una maximizador de la función de adquisición sobre $x$, donde la función de adquisición se calcula usando la distribución de probabilidad actual.\n",
    "    - Se evalúa $y_n=f(x_n)$.\n",
    "    - Se incrementa $n$.\n",
    "- Se devuelve el punto evaluado con una mayor $f(x)$ o el punto con la mayor media posterior.   \n",
    "\n",
    "Para implementar un modelo de optimización bayesiana en PyTorch, el tipo de librería que usemos va a depender del grado de control que queramos tener sobre las diferentes fases del ciclo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos tener un control total y gestionar nosotros el ciclo hay que utilizar directamente BoTorch. Sin embargo, si queremos centrarnos en las partes principales del modelo y no gestionar el ciclo es mejor utilizar Ax.\n",
    "\n",
    "Ax nos ofrece tres APIs (Loop, Service, and Developer) de experimentación secuencial que se diferencian en el nivel de customización. Loop es la más sencilla de usar y Developer la más customizable.\n",
    "\n",
    "A continuación vamos a ver un ejemplo en Colab usando la **API  Loop** y el método *optimize*, que realiza todos los pasos de la optimización bayesiana y devuelve los parámetros optimizados. Cuando llamamos a optimize tenemos que especificar, entre otros:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los parámetros o conjunto factible del modelo y su rango de variación.\n",
    "- La función de evaluación o función objetivo a utilizar, que tendremos que definir a parte o en la propia llamada. Hemos definido la función de Rosenbrock, mínimo en (1, 1), y una función convexa con mínimo en (0.4, 0.7).\n",
    "- Si es un problema de *minimización* o *maximización*.\n",
    "- El nombre del objetivo y del experimento.\n",
    "- El número de iteraciones del ciclo N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Será necesario instalar la librería ax-platform:\n",
    "# pip install ax-platform\n",
    "\n",
    "from ax import optimize\n",
    " \n",
    "def rosenbrock_function(parameterization):\n",
    "  x=parameterization.get(f\"x{1}\")\n",
    "  y=parameterization.get(f\"x{2}\")\n",
    "  z = (1-x)**2 + 100*(y-x**2)**2\n",
    "  return z\n",
    " \n",
    "def convex_function(parameterization):\n",
    "  x=parameterization.get(f\"x{1}\")\n",
    "  y=parameterization.get(f\"x{2}\")\n",
    "  z = (x-0.4)**2 + (y-0.7)**2\n",
    "  return z\n",
    " \n",
    "best_parameters, best_values, experiment, model = optimize(\n",
    "  parameters=[\n",
    "   {\n",
    "   \"name\": \"x1\",\n",
    "   \"type\": \"range\",\n",
    "   \"bounds\": [-3.0, 3.0],\n",
    "   },\n",
    "   {\n",
    "   \"name\": \"x2\",\n",
    "   \"type\": \"range\",\n",
    "   \"bounds\": [-3.0, 3.0],\n",
    "   },\n",
    "  ],\n",
    "  experiment_name=\"test\",\n",
    "  objective_name=\"Rosenbrock\",\n",
    "  evaluation_function=rosenbrock_function,\n",
    "  minimize=True,\n",
    "  total_trials=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez ejecutado el modelo usando las funciones de evaluación, nos devuelve los mejores parámetros encontrados.\n",
    "\n",
    "Se observa que, con la funcion de Rosenbrock, el modelo tarda más en converger al mínimo (1,1) que con una función convexa típica."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
