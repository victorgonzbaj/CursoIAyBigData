{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP (Procesamiento de Lenguaje Natural) con Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook vamos a ver la librería PyTorch-NLP, que es una librería abierta para procesamiento de lenguaje natural basada en PyTorch y que viene con módulos interesantes de datasets, embeddings preentrenados, codificadores de texto, redes neuronales, etc.\n",
    "\n",
    "El paquete **torchnlp.datasets** tiene módulos para descargar, almacenar y cargar datasets para procesamiento de lenguaje natural. Los módulos devuelven objetos *torch.utils.data.Dataset*, como los que vimos en el notebook sobre estas clases. Estos objetos tienen métodos para elegir y seleccionar elementos y se puedan pasar al *dataloader* para el proceso de carga y entrenamiento.\n",
    "\n",
    "A continuación, instalamos la libreria **pytorch-nlp** y vemos el dataset IMDB que contiene revisiones de películas con su correspondiente clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pip install pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 84.1MB [00:40, 2.06MB/s]                              \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchnlp.datasets import imdb_dataset\n",
    "\n",
    "#Creamos un objeto dataset con los datos\n",
    "dataset1 = imdb_dataset(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!',\n",
       "  'sentiment': 'pos'},\n",
       " {'text': 'Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.',\n",
       "  'sentiment': 'pos'},\n",
       " {'text': 'Brilliant over-acting by Lesley Ann Warren. Best dramatic hobo lady I have ever seen, and love scenes in clothes warehouse are second to none. The corn on face is a classic, as good as anything in Blazing Saddles. The take on lawyers is also superb. After being accused of being a turncoat, selling out his boss, and being dishonest the lawyer of Pepto Bolt shrugs indifferently \"I\\'m a lawyer\" he says. Three funny words. Jeffrey Tambor, a favorite from the later Larry Sanders show, is fantastic here too as a mad millionaire who wants to crush the ghetto. His character is more malevolent than usual. The hospital scene, and the scene where the homeless invade a demolition site, are all-time classics. Look for the legs scene and the two big diggers fighting (one bleeds). This movie gets better each time I see it (which is quite often).',\n",
       "  'sentiment': 'pos'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#La longitud de la muestra para entrenamiento es de 25000\n",
    "print(len(dataset1))\n",
    "\n",
    "#Vemos los cuatro primeros\n",
    "dataset1[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos la calificaión del primero \n",
    "dataset1[0]['sentiment'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, extraemos los valores del diccionario en dos listas, una para el texto y otra para las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "leng=25000\n",
    "\n",
    "text=[]\n",
    "label=[]\n",
    "for i in range(leng):      \n",
    "        input=dataset1[i]['text']\n",
    "        output=dataset1[i]['sentiment']   \n",
    "        text.append(input)\n",
    "        label.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paquete **torchnlp.encoders** tiene clases para codificar texto en tensores y viceversa. A continuación vamos a ver la clase *WhitespaceEncoder* que codifica un texto separándolo por los espacios en blanco. Importamos el paquete, definimos el texto necesario para construir el diccionario y creamos un objeto *WhitespaceEncoder* pasándole este texto.\n",
    "\n",
    "Después mostramos el tamaño del diccionario, la lista de tokens del diccionario y por último codificamos un texto ejemplo usando el objeto creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<unk>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<copy>',\n",
       " 'Esto',\n",
       " 'es',\n",
       " 'un',\n",
       " 'ejemplo',\n",
       " 'de',\n",
       " 'bloque',\n",
       " 'texto',\n",
       " 'Se',\n",
       " 'va',\n",
       " 'a',\n",
       " 'utilizar',\n",
       " 'para',\n",
       " 'tokenizar']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchnlp.encoders.text import WhitespaceEncoder\n",
    "\n",
    "loaded_data = [\"Esto es un ejemplo de bloque de texto\", \"Se va a utilizar para tokenizar\"]\n",
    "encoder = WhitespaceEncoder(loaded_data)\n",
    "print(encoder.vocab_size)\n",
    "encoder.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15,  7,  8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode(\"utilizar un ejemplo\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paquete *torchnlp.word_to_vector* tiene varios embeddings preentrenados. A continuación descargamos el modelo *Glove*. Cargamos la representación (embedding) de la palabra “Hello”, “Hi”, “Welcome” y “Car” y calculamos la diferencia entre dichos vectores usando el error cuadrático medio. Vemos como la palabra más cercana a “Hello” es “Hi” y la más lejana “Car”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "glove.840B.300d.zip: 2.18GB [11:02, 3.28MB/s]                                \n",
      "100%|██████████| 2196017/2196017 [02:28<00:00, 14821.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchnlp.word_to_vector import GloVe\n",
    "\n",
    "embedd = GloVe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0457)\n",
      "tensor(0.0792)\n",
      "tensor(0.2429)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n1=embedd['Hello']\n",
    "n2=embedd['Hi']\n",
    "n3=embedd['Welcome']\n",
    "n4=embedd['Car']\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "dev1=loss(n1,n2)\n",
    "print(dev1)\n",
    "dev2=loss(n1,n3)\n",
    "print(dev2)\n",
    "dev3=loss(n1,n4)\n",
    "print(dev3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
