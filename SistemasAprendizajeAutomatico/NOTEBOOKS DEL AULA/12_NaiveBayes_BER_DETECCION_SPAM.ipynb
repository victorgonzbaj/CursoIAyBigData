{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## ALGORITMO NAIVE-BAYES BERNOULLI - DETECCIÓN DE SPAM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importamos librerías necesarias.  \n",
    "Cargamos dataset usando un URL y a través de un REQUESTS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T18:49:43.387355900Z",
     "start_time": "2024-02-13T18:49:42.245737200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparación del dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5171, 4)\n",
      "Index(['Unnamed: 0', 'label', 'text', 'label_num'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cargamos dataset\n",
    "sms_data = pd.read_csv(\"./datasets/spam_ham_dataset.csv\") \n",
    "print(sms_data.shape)\n",
    "print(sms_data.columns)\n",
    "sms_data = sms_data.drop(['Unnamed: 0'],axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T18:49:46.051946500Z",
     "start_time": "2024-02-13T18:49:45.996535300Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generación del conjunto de características y de la clase\n",
    "\n",
    "El **CountVectorizer** proporciona una manera simple de tokenizar una colección de documentos de texto y construir un vocabulario de palabras conocidas.\n",
    "\n",
    "En el código que hay a continuación, dado que los datos de texto se utilizan para entrenar el clasificador, se convierte el texto en una matriz que comprende números utilizando **Count Vectorizer** para que el un buen funcionamiento del modelo.\n",
    "\n",
    "Respecto al dataset, se utiliza sólo la columna \"text\" como característica, ya que contiene la información de mayor relevancia y, como dato de salida, se utiliza la columna \"label_num\", que se transforma en la y de nuestro modelo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X =sms_data[\"text\"].values\n",
    "y = sms_data[\"label_num\"].values\n",
    "# creating count vectorizer object\n",
    "cv = CountVectorizer()\n",
    "#tranforming values\n",
    "X = cv.fit_transform(X)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T18:49:49.229320400Z",
     "start_time": "2024-02-13T18:49:48.642642Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Partición en conjuntos TRAIN y TEST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T18:49:53.859478400Z",
     "start_time": "2024-02-13T18:49:53.851024Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Construcción del modelo y entrenamiento"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bnb = BernoulliNB(binarize=0.0)\n",
    "model = bnb.fit(X_train, y_train)\n",
    "y_pred = bnb.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T18:49:56.191006500Z",
     "start_time": "2024-02-13T18:49:56.168679100Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluación del modelo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91       732\n",
      "           1       0.92      0.56      0.70       303\n",
      "\n",
      "    accuracy                           0.86      1035\n",
      "   macro avg       0.88      0.77      0.80      1035\n",
      "weighted avg       0.87      0.86      0.84      1035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T18:49:58.844587900Z",
     "start_time": "2024-02-13T18:49:58.788457500Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusión\n",
    "Del informe de clasificación se desprende que la accuracy, el recall y el F1 score de la clase 0 son de 0,84, 0,98 y 0,91 respectivamente, mientras que para la clase 1 la accuracy, el recall y el F1 score son de 0,92, 0,56 y 0,70 respectivamente.  \n",
    " Dado que el 13% del conjunto de datos está compuesto por la categoría spam, el valor de recall disminuye.   \n",
    " La accuracy global del modelo es del 86%, lo cúal indica que es un buen modelo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
