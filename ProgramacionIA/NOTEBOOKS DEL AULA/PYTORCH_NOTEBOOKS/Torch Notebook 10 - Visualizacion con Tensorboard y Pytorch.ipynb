{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización en Pytorch usando Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard es una de las herramientas más potentes de visualización en machine learning. Permite realizar funciones interesantes como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizar métricas como la pérdida y la exactitud.\n",
    "- Visualizar los grafos creados por el modelo.\n",
    "- Ver histógramas de los parámetros y como cambian en el tiempo.\n",
    "- Ver imágenes y datos de de audio o texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch permite trabajar con TensorBoard. En la versión PyTorch 1.1.0, TensorBoard se soportaba de manera experimental pero desde la versión PyTorch 1.2.0 ya está integrada plenamente.\n",
    "\n",
    "Primero, tendremos que instalar la extensión de Tensorboard para notebooks y cargarla, como se ve a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q tf-nightly\n",
    "# Carga la extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, crearemos el directorio donde guardaremos los logs que almacene TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "logs_base_dir = \"runs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una clase con varias capas de redes neuronales, instanciamos un objeto de esta clase y lo optimizamos con autograd.\n",
    "\n",
    "Para usar TensorBoard, primero creamos un objeto SummaryWriter() que permite crear un archivo de eventos en el directorio indicado (por defecto sería “runs”) y añadir eventos en el archivo.\n",
    "\n",
    "Después, le indicamos qué eventos guardar en el archivo creado. En este caso, vamos a registrar dos tipos de eventos o logs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El grafo creado por el modelo, lo que hará con writer.add_graph(net,input).\n",
    "- La pérdida en cada iteración, que la registraremos con writer.add_scalar(‘training loss’,loss.data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size= 10\n",
    "output_size= 1   \n",
    "hidden_size= 50   \n",
    "train_size= 5000\n",
    "batch_size=10    \n",
    "num_epochs= 10     \n",
    "learning_rate =1e-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "len=int(train_size/batch_size)\n",
    "\n",
    "input=torch.normal(0, 1, size=(train_size, input_size))\n",
    "input=input/input.max()\n",
    "\n",
    "linear1=nn.Linear(input_size, output_size)\n",
    "\n",
    "with torch.no_grad():\n",
    "  label=linear1(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
    "        self.relu1 = nn.ReLU()                          \n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) \n",
    "    \n",
    "    def forward(self, x):                              \n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = Net(input_size, hidden_size, output_size)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len):      \n",
    "        optimizer.zero_grad()\n",
    "        input1=input[i*batch_size:(i+1)*batch_size]\n",
    "        label1=label[i*batch_size:(i+1)*batch_size]                             \n",
    "        output = net(input1)                             \n",
    "        loss = criterion(output, label1)                 \n",
    "        loss.backward()                                   \n",
    "        optimizer.step()                                  \n",
    "        writer.add_scalar('training loss',loss.data)                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net,input)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora llamaremos a Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9496), started 0:03:13 ago. (Use '!kill 9496' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6bb708efa42941dc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6bb708efa42941dc\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, borraremos el directorio creado para almacenar el archivo de logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
