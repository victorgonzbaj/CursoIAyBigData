{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas que califican una clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se carga del conjunto Iris desde la librería scikit-learn\n",
    "\n",
    "   - Primero se vuelca a un DataFrame, con 4 columnas con sus caracteristicas y una columna con la clasificación objetivo\n",
    "   - Se muestra la descripción de cada uno de los valores (0, 1, 2) objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:28:48.648183400Z",
     "start_time": "2024-02-01T11:28:47.758042300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n0                5.1               3.5                1.4               0.2   \n1                4.9               3.0                1.4               0.2   \n2                4.7               3.2                1.3               0.2   \n3                4.6               3.1                1.5               0.2   \n4                5.0               3.6                1.4               0.2   \n\n   target  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target']=iris['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se divide el conjunto de datos de entrada en Entrenamiento (75%) y Validación (25%). Conjuntos Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:28:53.189996200Z",
     "start_time": "2024-02-01T11:28:53.143823200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df.values[:,0:4], df.values[:,4]\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.25, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se hace el ajuste por Naïve-Bayes con la clase disponible en sk-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:29:01.440442600Z",
     "start_time": "2024-02-01T11:29:01.387884500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GaussianNB()",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Confusión\n",
    "Para el caso de un clasificador binario, una matriz de confusion es una matriz cuadrada $2 \\times 2$ que proporciona los :\n",
    "- Verdaderos Positivos (VP): valores positivos correctos\n",
    "- Verdaderos Negativos (VN): valores negativos correctos\n",
    "- Falsos Positivos (FP): valores positivos incorrectos\n",
    "- Falsos Negativos (FN): valores negativos incorrectos\n",
    "\n",
    "Además consideramos la realidad representada a la izquierda y la predicción en la barra superior:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./img/Mat_Confusion.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro conjunto __Iris__ al disponer de 3 clases distintas, en lugar de una matriz $2 \\times 2$ dispondremos una matriz $3 \\times 3$, que es posible calcular directamente con la librería sk-learn.\n",
    "\n",
    "Como se observa hay __un único elemento mal__ en el conjunto de __test__ predicho que aparece como versicolor, cuando debe ser virginica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:30:32.906435Z",
     "start_time": "2024-02-01T11:30:32.353940600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = clf_NB.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=iris['target_names']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratios que miden la precisión de la clasificación\n",
    "\n",
    "El __error__ de predicción (<b>ERR</b>) y la __exactitud__ (<b>ACC</b>, accuracy) mide cuantos ejemplos están mal clasificados (__calidad del modelo__). El error de predicción se calcula:\n",
    "\n",
    "$$ERR=\\frac{FP+FN}{VP+FN+FP+VN}$$\n",
    "\n",
    "La exactitud es:\n",
    "\n",
    "$$ACC=\\frac{VP+VN}{VP+FN+FP+VN}=1-ERR$$\n",
    "\n",
    "Otro ratio para medir la calidad es la __Precisión__ (__PRE__, Precision), ratio de verdaderos positivos frente a positivos de la predicción:\n",
    "\n",
    "$$PRE=\\frac{VP}{VP+FP}$$\n",
    "\n",
    "Un __clasificador perfecto__ tendrá __ERR = 0__, __ACC = 1__ y __PRE = 1__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un conjunto de datos de entrenamiento donde __las clases están equilibradas__ son suficientes los anteriores ratios y también son utiles los ratios:\n",
    "\n",
    "- __Sensibilidad - SEN, TPR__ _(True Positive Rate o Razón de Verdaderos Positivos)_ : Es la probabilidad de que un positivo sea realmente positivo o capacidad del estimador para dar casos positivos (\"_enfermos_\"). Es la tasa de verdaderos positivos frente a positivos. Este parámetro también se denomina recall o exhaustividad.\n",
    "- __Especificidad - SPC, TNR__ _(True Negative Rate o Razón de Verdaderos Negativos)_ : Es la probabilidad de que un negativo sea realmente negativo o capacidad del estimador de dar casos negativos (\"_sanos_\"). Tasa de verdaderos negativos frente a negativos.\n",
    "\n",
    "$$SEN=\\frac{VP}{P}=\\frac{VP}{VP+FN}$$\n",
    "\n",
    "$$SPC=\\frac{VN}{N}=\\frac{VN}{VN+FP}$$\n",
    "\n",
    "Otros ratios interesantes que se pueden formar con la matriz de confusión son:\n",
    "\n",
    "- __Razón de Falsas Alarmas - FPR__ _(False Posive Rate o Ratio de Falsos Positivos)_ : Es la tasa de falsos positivos entre los positivos reales. Es igual __1 - Especificidad__:\n",
    "\n",
    "$$FPR =\\frac{FP}{N}=\\frac{FP}{VN+FP}=1-SPC$$ \n",
    "\n",
    "Un __clasificador perfecto__ tendrá __SEN=1__, __SPC=1__ y __FPR=0__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 - Score\n",
    "El __Valor-F__, o __F1-score__, combina las medidas de __precision y sensibilidad__ en un sólo valor. Permite comparar el rendimiento combinado de la precisión y la sensibilidad entre varios modelos.:\n",
    "\n",
    "$$F1=2\\frac{PRE \\times SEN}{PRE + SEN}$$\n",
    "\n",
    "El F1-Score es de gran utilidad cuando la distribución de las clases es desigual.\n",
    "\n",
    "Conforme a los estadísticos de Precisión y Sensibilidad se tienen las siguientes posibilidades:\n",
    "\n",
    "- Alta precisión y alta sensibilidad: el modelo de Machine Learning escogido maneja perfectamente esa clase.\n",
    "- Alta precisión y baja sensibilidad: el modelo de Machine Learning escogido no detecta la clase muy bien, pero cuando lo hace es altamente confiable.\n",
    "- Baja precisión y alta sensibilidad: El modelo de Machine Learning escogido detecta bien la clase,  pero también incluye muestras de la otra clase.\n",
    "- Baja precisión y baja sensibilidad: El modelo de Machine Learning escogido no logra clasificar la clase correctamente.\n",
    "\n",
    "Un __clasificador perfecto__ (__SEN=1__ y __ESP=1__) tendrá __F1=1__.\n",
    "\n",
    "Estos ratios están implementados en la __librería sklearn.metrics__\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "__NOTA A sklearn.metrics__:__ Algunas métricas se definen esencialmente para tareas de clasificación binaria (por ejemplo, f1_score, roc_auc_score). En estos casos, por defecto solo se evalúa la etiqueta positiva, asumiendo por defecto que la clase positiva está etiquetada como 1 (aunque esto puede configurarse a través del __parámetro pos_label__)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consejos Generales (*)\n",
    "\n",
    "- __La precisión__ es un gran estadístico, Pero es útil únicamente cuando se tienen “datasets” simétricos (la cantidad de casos de la clase 1 y de las clase 2 tienen magnitudes similares)\n",
    "\n",
    "- __El indicador F1__ de la matriz de confusión es útil si se  tiene una distribución de clases desigual.\n",
    "\n",
    "- __Elija mayor precisión__ para conocer qué tan seguro está de los verdaderos positivos, Mientras que la sensibilidad o  “Recall” le servirá para saber si no está perdiendo positivos.\n",
    "\n",
    "- __Las Falsas Alarmas:__  Por ejemplo,  si cree que es mejor en su caso tener falsos positivos que falsos negativos, utilice una sensibilidad alta  (Recall) , cuando la aparición de falsos negativos le resulta inaceptable pero no le importa tener falsos positivos adicionales (falsas alarmas).\n",
    "\n",
    "Por ejemplo si es preferible que algunas personas sanas sean etiquetadas como diabéticas en lugar de dejar a una persona diabética etiquetada como sana.\n",
    "\n",
    "- __Elija precisión ( precision en inglés)__  para estar más seguro de sus verdaderos positivos. por ejemplo, correos electrónicos no deseados.  En este caso se prefiere tener algunos correos electrónicos “no deseados” en su bandeja de entrada en lugar de tener correos electrónicos “reales” en su bandeja de SPAM.\n",
    "\n",
    "- __Elija alta Especificidad__:  si desea identificar los verdaderos negativos, o lo que es igual cuando no desea falsos positivos. Por ejemplo conductores  y las pruebas de alcoholemia, donde sería intolerable que un falso positivo, libre de alcohol, sea penado.\n",
    "\n",
    "_(*)_ {cite:p}`Barrios_2019`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeramente obtenemos la predicción del modelo sobre el conjunto de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:32:49.640176300Z",
     "start_time": "2024-02-01T11:32:49.616716600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([2., 0., 0., 0., 1., 0., 1., 1., 0., 1., 2., 2., 2., 1., 2., 1., 2.,\n       1., 1., 1., 1., 2., 2., 1., 0., 0., 0., 1., 2., 0., 0., 2., 1., 0.,\n       0., 1., 2., 2.])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_NB.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y calculamos los indicadores\n",
    "\n",
    "En el cálculo de la __precisión__ si hay más de 2 clases distintas es obligatorio el parametro __average__ con las opciones:\n",
    "\n",
    "- '__binary__': Informa únicamente los resultados de la clase especificada por __pos_label__. Esto es aplicable solo si los destinos (y_ {true, pred}) son binarios.\n",
    "- '__micro__': Calcula métricas a nivel global contando el total de verdaderos positivos, falsos negativos y falsos positivos.\n",
    "- '__macro__': Calcula métricas para cada etiqueta y encuentre su media no ponderada. Esto no tiene en cuenta el desequilibrio de etiquetas.\n",
    "- '__weighted__' ('ponderado'): Calcula métricas para cada etiqueta y encuentre su promedio ponderado por soporte (el número de instancias verdaderas para cada etiqueta). Altera la métrica 'macro' para tener en cuenta el desequilibrio de etiquetas; puede resultar en una puntuación F que no se encuentra entre la precisión y el recuerdo.\n",
    "- '__samples__' ('muestras'): Calcula métricas para cada instancia y encuentre su promedio (solo es significativo para la clasificación de múltiples etiquetas donde esto difiere de la puntuación de precisión).\n",
    "\n",
    "De forma análoga se encuentra el parámetro __average__ en las funciones __recall_score__ y __f1_score__ usadas para el cálculo de los otros 2 indicadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:33:08.427996700Z",
     "start_time": "2024-02-01T11:33:08.396646400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud - Accuracy: 0.974\n",
      "Precision: 0.974\n",
      "Sensibilidad - Recall: 0.974\n",
      "F1: 0.974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "print('Exactitud - Accuracy: %.3f' % accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='micro'))\n",
    "print('Sensibilidad - Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='micro'))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__El ratio que se utilizará a partir de ahora es la exactitud o accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:33:20.060456Z",
     "start_time": "2024-02-01T11:33:20.043497900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud - Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Exactitud - Accuracy: %.3f' % accuracy_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Control del error de Clasicación\n",
    "\n",
    "__Cuando clasificamos nuevas instancias__:\n",
    "\n",
    "- Interesa reducir la __tasa de error esperada__.\n",
    "- Realizar promedios reduce la varianza: $Var(\\bar{X}) = \\frac{1}{N} Var(X)$\n",
    "- Problema: sólo tenemos __un conjunto de entrenamiento__.\n",
    "- Una de las técnicas habituales es la llamada __bootstrapping__: se estima el error generando $N$ muestras equiprobables con reemplazamiento del conjunto de entrenamiento $D_N$.\n",
    "- Como las muestras con reemplazamiento tienen el mismo tamaño que $D_N$, se espera una fracción $1 - \\frac{1}{e}$ de registros en el conjunto de entrenamiento: es la llamada __regla $0.632$__ para el estimador bootstrap.\n",
    "\n",
    "### Explicación\n",
    "\n",
    "Dada una muestra $x_1,\\ldots,x_n$ original, el método bootstrap consiste en tomar nuevas muestras a partir de ella __con reemplazamiento__. \n",
    "\n",
    "Al generar una nueva muestra, tomamos elementos de la muestra original uno a uno. La probabilidad de escoger, por ejemplo, el elemento $x_1$ es $1/n$, por tanto la probabilidad de no tomarlo es $1-1/n$. Como las nuevas muestras tienen $n$ elementos, tomados de manera independiente, con reemplazamiento, la probabilidad que $x_1$ no esté en la nueva muestra es $(1-1/n)^n$.\n",
    "\n",
    "Al hacer $n\\to\\infty$ tenemos $1/e$ que es la probabilidad de que un elemento no haya sido escogido.\n",
    "\n",
    "Por lo tanto, la probabilidad que un elemento esté en las muestras tomadas con bootstrapping es $1-1/e\\approx0.632$.\n",
    "\n",
    "Esto quiere decir que cada una de las muestras que se crean usando el método bootstraping, tiene, en media, un 63% del conjunto original.\n",
    "\n",
    "\n",
    "## Una mejora de la precisión \n",
    "\n",
    "__Bagging (\"bootstrap aggregating\")__:\n",
    "\n",
    "- Realizamos N réplicas del conjunto de entrenamiento mediante __bootstrapping__.\n",
    "- En media, cada conjunto de entrenamiento tendrá un 63% de las instancias del conjunto inicial.\n",
    "- Utilizamos cada una de las réplicas para clasificar el conjunto de validación.\n",
    "- Usamos la regla del __voto mayoritario__ para asignar las clases.\n",
    "- Este método ayuda a corregir resultados de clasificadores \"inestables\".\n",
    "\n",
    "<img src=\"./img/Bagging.png\" width=\"500px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación del error por Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:38:30.265650900Z",
     "start_time": "2024-02-01T11:38:30.141143900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exactitud: 0.962 +/- 0.019\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "## Hacemos el entrenamiento de los clasificadores\n",
    "NumRepeticiones = 100 # hacemos 100 muestras con bootstrap\n",
    "NumMuestras = X_train.shape[0] # el número de muestras totales en X_train\n",
    "indices = np.arange(X_train.shape[0]) # un listado con los índices de X_train 1,2,...,NumMuestras\n",
    "clf_Boot = GaussianNB()\n",
    "scores=[]\n",
    "\n",
    "for rep in np.arange(NumRepeticiones):\n",
    "    indicesNew = np.random.choice(indices,NumMuestras,replace=True) #nuevos indices cogidos al azar\n",
    "    X_train_Boot = X_train[indicesNew] # tomamos los datos X de esos indices\n",
    "    y_train_Boot = y_train[indicesNew] # y sus categorías\n",
    "    clf_Boot.fit(X_train_Boot, y_train_Boot)\n",
    "    scores.append(clf_Boot.score(X_test, y_test))\n",
    "print('\\nExactitud: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación del Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:38:34.255574400Z",
     "start_time": "2024-02-01T11:38:34.189222100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "## Hacemos el entrenamiento de los clasificadores\n",
    "NumRepeticiones = 100 # hacemos 100 muestras con bootstrap\n",
    "NumMuestras = X_train.shape[0] # el número de muestras totales en X_train\n",
    "indices = np.arange(X_train.shape[0]) # un listado con los índices de X_train 1,2,...,NumMuestras\n",
    "clf_Bagg = [GaussianNB() for i in range(NumRepeticiones)]\n",
    "\n",
    "for rep in np.arange(NumRepeticiones):\n",
    "    indicesNew = np.random.choice(indices,NumMuestras,replace=True) #nuevos índices cogidos al azar\n",
    "    X_train_Bagg = X_train[indicesNew] # tomamos los datos X de esos indices\n",
    "    y_train_Bagg = y_train[indicesNew] # y sus categorías\n",
    "    clf_Bagg[rep].fit(X_train_Bagg, y_train_Bagg)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ahora se hace uso de N clasificadores entrenados para predecir con voto mayoritario el conjunto de test__ \n",
    "\n",
    "__Se usa la moda como forma de obtener la etiqueta más votada__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T11:41:11.904591400Z",
     "start_time": "2024-02-01T11:41:11.845496400Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [38, 2]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m y_predMult \u001B[38;5;241m=\u001B[39m [clf_Bagg[rep]\u001B[38;5;241m.\u001B[39mpredict(X_test) \u001B[38;5;28;01mfor\u001B[39;00m rep \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(NumRepeticiones)]\n\u001B[0;32m      5\u001B[0m y_predVoto \u001B[38;5;241m=\u001B[39m stats\u001B[38;5;241m.\u001B[39mmode((y_predMult)[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExactitud - Accuracy: \u001B[39m\u001B[38;5;132;01m%.4f\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m accuracy_score(y_true\u001B[38;5;241m=\u001B[39my_test, y_pred\u001B[38;5;241m=\u001B[39my_predVoto))\n",
      "File \u001B[1;32mE:\\Users\\Jordi\\anaconda3\\envs\\ceiadb\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    187\u001B[0m validate_parameter_constraints(\n\u001B[0;32m    188\u001B[0m     parameter_constraints, params, caller_name\u001B[38;5;241m=\u001B[39mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\n\u001B[0;32m    189\u001B[0m )\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 192\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    194\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    198\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    199\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    200\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    201\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    202\u001B[0m     )\n",
      "File \u001B[1;32mE:\\Users\\Jordi\\anaconda3\\envs\\ceiadb\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001B[0m, in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Accuracy classification score.\u001B[39;00m\n\u001B[0;32m    156\u001B[0m \n\u001B[0;32m    157\u001B[0m \u001B[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;124;03m0.5\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[1;32m--> 221\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m _check_targets(y_true, y_pred)\n\u001B[0;32m    222\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32mE:\\Users\\Jordi\\anaconda3\\envs\\ceiadb\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_targets\u001B[39m(y_true, y_pred):\n\u001B[0;32m     60\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[0;32m     61\u001B[0m \n\u001B[0;32m     62\u001B[0m \u001B[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;124;03m    y_pred : array or indicator matrix\u001B[39;00m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 86\u001B[0m     check_consistent_length(y_true, y_pred)\n\u001B[0;32m     87\u001B[0m     type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     88\u001B[0m     type_pred \u001B[38;5;241m=\u001B[39m type_of_target(y_pred, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mE:\\Users\\Jordi\\anaconda3\\envs\\ceiadb\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    395\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[0;32m    396\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 397\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    398\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    399\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[0;32m    400\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [38, 2]"
     ]
    }
   ],
   "source": [
    "### ATENCIÓN: HAY QUE USAR EL VOTO MAYORITARIO, POR TANTO HAY QUE GUARDAR TODOS LOS VOTOS\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_predMult = [clf_Bagg[rep].predict(X_test) for rep in range(NumRepeticiones)]\n",
    "y_predVoto = stats.mode((y_predMult)[0][0])\n",
    "print('Exactitud - Accuracy: %.4f' % accuracy_score(y_true=y_test, y_pred=y_predVoto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación del Bagging (librería sk-learn)\n",
    "\n",
    "En la librería sk-learn se encuentra una implementación del Bagging para clasificadores en la sublibrería __BaggingClassifier__:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
    "\n",
    "Los __parámetros__ más importantes del constructor son:\n",
    "\n",
    "- __base_estimator__ : el estimador base que utiliza. Por defecto es __DecisionTreeClassifier__.\n",
    "- __n_estimators__ : número de estimadores, __por defecto son 10__.\n",
    "\n",
    "Los __métodos__ que se pueden invocar desde el objeto creado con el constructor son, entre otros:\n",
    "\n",
    "- __fit(X,y)__ : realiza el ajuste del modelo a partir de una conjunto __X__ de características y un conjuno __y__ de respuestas.\n",
    "- __predict(X)__ : predice las resupuestas de un conjunto de características __X__.\n",
    "- __score(X,y)__ : devuelve la exactitud o accuracy conocidos un conjunto de características __X__ y sus respuestas correctas __y__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud - Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bggC = BaggingClassifier()\n",
    "bggC.fit(X_train, y_train)\n",
    "print('Exactitud - Accuracy: %.4f' % bggC.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Se repite el Bagging cambiando el clasificador__\n",
    "\n",
    "Se usa el clasificador K-Vecinos\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud - Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bggC = BaggingClassifier(base_estimator=KNeighborsClassifier())\n",
    "bggC.fit(X_train, y_train)\n",
    "print('Exactitud - Accuracy: %.4f' % bggC.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Red'> <font size=\"5\"> <b>Información Complementaria</b></font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Es bueno el clasificador? P-Valor\n",
    "\n",
    "\n",
    "Un clasificador implica:\n",
    "\n",
    "- Un conjunto de datos D\n",
    "- Un clasificador entrenado, F, sobre D.\n",
    "- Una medida de la exactitud del clasificador, accuracy (ACC).\n",
    "\n",
    "Se tiene un único dato (ACC) y con eso no se puede hacer nada. Es como si mide la altura de una persona, no dice nada acerca de la media de una población\n",
    "\n",
    "Entonces, __¿cómo contestar la pregunta anterior acerca de si un solo clasificador es bueno?__\n",
    "\n",
    "Usando un test de permutación se mide la probabilidad de que el ACC alcanzado haya sido por pura casualidad. El p-valor representará la fracción de datos aleatorios en los que el clasificador se comporta igual o mejor que en los datos reales que tenemos.\n",
    "\n",
    "En el fondo se está analizando si hay correlación entre X e Y. El clasificador se encarga de encontrar esta estructura/conexión, pero si ésta no existe, el clasificador no está cumpliendo su función, y no debe ser considerado un buen clasificador.\n",
    "\n",
    "__La hipótesis nula es que el clasificador que tenemos ha actuado por pura suerte__, es decir, no es bueno. Y el método consiste en:\n",
    "- Generar, a partir de los datos, nuevos conjuntos de datos “aleatorios”, realizando permutaciones de los que tenemos. Generamos conjuntos D’ a partir de D. El número de nuevos conjuntos es M.\n",
    "- Para cada nuevo conjunto de datos, D’, usamos el clasificador F, y hallamos una precisión ACC’\n",
    "- Contamos el número de veces que ACC’ es mejor que la ACC original que teníamos con los datos originales, lo llamamos “Cont”\n",
    "\n",
    "La formula para calcular el p-valor es\n",
    "\n",
    "$$p\\_valor = \\frac{Cont+1}{M+1}$$\n",
    "\n",
    "El p-valor representa la fracción de las muestra aleatorias en que el clasificador se comportó mejor que en los datos originales. __Por tanto, si el p-valor es pequeño, podemos decir que la ACC es significativa (significativamente alta) y el clasificador es significativo sobre la hipótesis nula, es decir, rechazamos la hipótesis nula.__\n",
    "\n",
    "Respecto a las versiones “randomizadas” de los datos, D’ (las permutaciones), es importante subrayar que, idealmente, __deberían tomarse__ todas las posibles permutaciones de los datos, pero esto es costosísimo computacionalmente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud - Accuracy Inicial: 0.974\n"
     ]
    }
   ],
   "source": [
    "## Entrenamiento inicial y toma del ACC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(X_train, y_train)\n",
    "y_pred=clf_NB.predict(X_test)\n",
    "ACC_Ini = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print('Exactitud - Accuracy Inicial: %.3f' % ACC_Ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Se mide la Exactitud en M permutaciones__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.009900990099009901, 0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "## Hacemos el entrenamiento de los clasificadores\n",
    "NumRepeticiones = 100 # hacemos 100 muestras con bootstrap\n",
    "NumMuestras = X_train.shape[0] # el número de muestras totales en X_train\n",
    "indices = np.arange(X_train.shape[0]) # un listado con los índices de X_train 1,2,...,NumMuestras\n",
    "clf_Boot = GaussianNB()\n",
    "Cont = 0\n",
    "\n",
    "for rep in np.arange(NumRepeticiones):\n",
    "    indicesNew = np.random.choice(indices,NumMuestras,replace=True) #nuevos indices cogidos al azar\n",
    "    X_train_Boot = X_train[indicesNew] # tomamos los datos X de esos indices\n",
    "    y_train_Boot = y_train[indicesNew] # y sus categorías\n",
    "    clf_Boot.fit(X_train_Boot, y_train_Boot)\n",
    "    if clf_Boot.score(X_test, y_test) > ACC_Ini:\n",
    "        Cont +=1\n",
    "\n",
    "p_valor = (Cont+1)/(NumRepeticiones + 1)\n",
    "p_valor, Cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Luego podemos concluir que el clasificador GaussianNB para el conjunto Iris es bueno__\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
